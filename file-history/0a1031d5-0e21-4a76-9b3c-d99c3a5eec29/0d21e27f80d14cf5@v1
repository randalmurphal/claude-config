"""
Semantic searcher - Stage 1 of intelligent retrieval.

Responsibility: Qdrant semantic search with quality gate.
Single responsibility: Find semantically relevant memories with score threshold.
"""

import logging
from typing import List, Tuple, Optional
import numpy as np

from prism_mcp.models.embedder import get_embedder
from prism_mcp.storage.qdrant_manager import (
    QdrantManager,
    MEMORY_TYPE_TO_COLLECTION,
    COLLECTION_E5,
)
from prism_mcp.core.memory_engine import Memory, MemoryTier
from prism_mcp.utils.config import get_config
from datetime import datetime

logger = logging.getLogger(__name__)


class SemanticSearcher:
    """
    Stage 1: Semantic search with quality gate.

    Uses Qdrant for vector similarity search with explicit score threshold.
    NO DEFAULTS - all config values required.
    """

    def __init__(self):
        """
        Initialize semantic searcher from configuration.

        Raises:
            RuntimeError: If configuration missing or invalid
        """
        self.config = get_config()
        self.embedder = get_embedder()
        self.qdrant = QdrantManager()

        self.min_similarity = (
            self.config.intelligent_retrieval.semantic.min_similarity_threshold
        )
        self.distance_metric = (
            self.config.intelligent_retrieval.semantic.distance_metric
        )

        if self.distance_metric not in ['cosine', 'dot', 'euclidean']:
            raise RuntimeError(
                f'Invalid distance_metric: {self.distance_metric}. '
                f'Must be one of: cosine, dot, euclidean'
            )

        logger.info(
            f'SemanticSearcher initialized with min_similarity={self.min_similarity}, '
            f'distance_metric={self.distance_metric}'
        )

    def search(
        self,
        query: str,
        limit: int,
        memory_type: str = 'research_note',
        min_score: Optional[float] = None,
        project_id: Optional[str] = None,
        branch: Optional[str] = None,
        tier_filter: Optional[MemoryTier] = None,
        augment: bool = False,
        include_deleted: bool = False,
    ) -> List[Tuple[Memory, float]]:
        """
        Semantic search with score threshold.

        Phase 2.3: Now supports query augmentation for E5 queries.

        Args:
            query: Search query text
            limit: Maximum number of results
            memory_type: Type of memory to search (routes to correct collection, defaults to research_note)
            min_score: Override minimum similarity score (defaults to config)
            project_id: Filter by project
            branch: Filter by branch
            tier_filter: Filter by memory tier
            augment: Apply query augmentation (E5 only, +33% near-miss precision)
            include_deleted: Include deleted symbols in results (default: False)

        Returns:
            List of (Memory, similarity_score) tuples
            Only returns memories with score >= min_score

        Raises:
            RuntimeError: If search fails
        """
        if not query:
            raise RuntimeError('query is required for semantic search')

        min_score_threshold = (
            min_score if min_score is not None else self.min_similarity
        )

        # Determine collection from memory_type
        collection = MEMORY_TYPE_TO_COLLECTION.get(memory_type)
        if not collection:
            raise RuntimeError(
                f"Unknown memory_type '{memory_type}'. "
                f'Valid types: {list(MEMORY_TYPE_TO_COLLECTION.keys())}'
            )

        # Generate query embedding with augmentation if requested and using E5
        if augment and collection == COLLECTION_E5:
            query_embedding = self.embedder.embed_with_e5(query, augment=True)
        else:
            query_embedding = self.embedder.generate_embedding(
                query, memory_type=memory_type
            )

        filter_conditions = {}
        filter_exclude = {}

        if tier_filter:
            filter_conditions['tier'] = tier_filter.value
        if project_id:
            filter_conditions['project_id'] = project_id
        if branch:
            filter_conditions['branch'] = branch

        # Exclude deleted symbols by default
        if not include_deleted:
            filter_exclude['is_deleted'] = True

        results = self.qdrant.search(
            collection_name=collection,
            query_vector=query_embedding,
            limit=limit,
            score_threshold=min_score_threshold,
            filter_conditions=filter_conditions if filter_conditions else None,
            filter_exclude=filter_exclude if filter_exclude else None,
            with_payload=True,
            with_vectors=False,
        )

        memories = []
        for result in results:
            memory = self._result_to_memory(result)
            similarity = result['score']
            memories.append((memory, similarity))

        logger.debug(
            f'Semantic search returned {len(memories)} results '
            f'(min_score={min_score_threshold:.2f})'
        )

        return memories

    def _result_to_memory(self, result: dict) -> Memory:
        """
        Convert Qdrant search result to Memory object.

        Args:
            result: Qdrant search result with payload

        Returns:
            Memory object reconstructed from payload

        Raises:
            RuntimeError: If required fields missing
        """
        payload = result['payload']

        required_fields = [
            'memory_id',
            'content',
            'memory_type',
            'tier',
            'created_at',
            'last_accessed',
            'access_count',
            'frustration_score',
            'related_memories',
        ]

        for field in required_fields:
            if field not in payload:
                raise RuntimeError(
                    f"Required field '{field}' missing from memory payload. "
                    f'Memory ID: {payload.get("memory_id", "unknown")}'
                )

        memory = Memory(
            memory_id=payload['memory_id'],
            content=payload['content'],
            memory_type=payload['memory_type'],
            tier=MemoryTier(payload['tier']),
            embedding=np.array([]),
            created_at=datetime.fromisoformat(payload['created_at']),
            last_accessed=datetime.fromisoformat(payload['last_accessed']),
            access_count=payload['access_count'],
            frustration_score=payload['frustration_score'],
            project_id=payload.get('project_id'),
            branch=payload.get('branch'),
            session_id=payload.get('session_id'),
            related_memories=payload['related_memories'],
            derived_from=payload.get('derived_from'),
            file_path=payload.get('file_path'),
            symbol_name=payload.get('symbol_name'),
            symbol_type=payload.get('symbol_type'),
            line_start=payload.get('line_start'),
            line_end=payload.get('line_end'),
            signature=payload.get('signature'),
            git_sha=payload.get('git_sha'),
            applicable_roles=payload.get('applicable_roles'),
            applicable_task_types=payload.get('applicable_task_types'),
            applicable_phases=payload.get('applicable_phases'),
        )

        return memory
