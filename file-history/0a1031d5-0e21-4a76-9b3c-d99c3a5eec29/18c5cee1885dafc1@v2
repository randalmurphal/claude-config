"""
API-based embedding providers (Tier 0 - PREMIUM_API)

Provides wrappers for:
- Voyage AI (voyage-code-3, voyage-3-large)
- Future: OpenAI, Cohere, etc.
"""

import logging
import os
import time
from typing import List, Tuple

import numpy as np

logger = logging.getLogger(__name__)


class VoyageEmbedder:
    """
    Voyage AI embedding client

    Models:
    - voyage-code-3: Optimized for code (1024d)
    - voyage-3-large: General purpose (1024d, 32K context)

    Free tier: 200M tokens
    Rate limits: Standard (with payment method)
    """

    def __init__(self, api_key: str, code_model: str = "voyage-code-3", general_model: str = "voyage-3-large"):
        """
        Initialize Voyage client

        Args:
            api_key: Voyage API key (get from https://www.voyageai.com/)
            code_model: Model for code embeddings
            general_model: Model for semantic embeddings
        """
        self.api_key = api_key
        self.code_model = code_model
        self.general_model = general_model

        # Lazy import
        try:
            import voyageai
            self.client = voyageai.Client(api_key=api_key)
            logger.info(f"Initialized Voyage AI client (code: {code_model}, general: {general_model})")
        except ImportError:
            logger.error("voyageai package not installed. Run: pip install voyageai")
            raise RuntimeError("voyageai package required for PREMIUM_API tier")

        # Track usage
        self.total_tokens_used = 0
        self.total_requests = 0

    def embed_code(self, texts: List[str], batch_size: int = 128) -> Tuple[np.ndarray, int]:
        """
        Embed code using voyage-code-3

        Args:
            texts: List of code snippets
            batch_size: Batch size for API calls

        Returns:
            (embeddings, tokens_used)
        """
        if not texts:
            return np.array([]), 0

        # Batch processing to avoid rate limits
        all_embeddings = []
        total_tokens = 0

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]

            try:
                result = self.client.embed(
                    texts=batch,
                    model=self.code_model,
                    input_type="document"
                )

                all_embeddings.extend(result.embeddings)
                total_tokens += result.total_tokens
                self.total_requests += 1

            except Exception as e:
                logger.error(f"Voyage API error (code): {e}")
                # Return zeros for failed embeddings
                all_embeddings.extend([np.zeros(1024).tolist() for _ in batch])

        self.total_tokens_used += total_tokens

        return np.array(all_embeddings), total_tokens

    def embed_semantic(self, texts: List[str], batch_size: int = 128) -> Tuple[np.ndarray, int]:
        """
        Embed semantic text using voyage-3-large

        Args:
            texts: List of text to embed
            batch_size: Batch size for API calls

        Returns:
            (embeddings, tokens_used)
        """
        if not texts:
            return np.array([]), 0

        all_embeddings = []
        total_tokens = 0

        for i in range(0, len(texts), batch_size):
            batch = texts[i:i+batch_size]

            try:
                result = self.client.embed(
                    texts=batch,
                    model=self.general_model,
                    input_type="document"
                )

                all_embeddings.extend(result.embeddings)
                total_tokens += result.total_tokens
                self.total_requests += 1

            except Exception as e:
                logger.error(f"Voyage API error (semantic): {e}")
                # Return zeros for failed embeddings
                all_embeddings.extend([np.zeros(1024).tolist() for _ in batch])

        self.total_tokens_used += total_tokens

        return np.array(all_embeddings), total_tokens

    def embed_query(self, query: str, query_type: str = "semantic") -> Tuple[np.ndarray, int]:
        """
        Embed a single query

        Args:
            query: Query text
            query_type: 'code' or 'semantic'

        Returns:
            (embedding, tokens_used)
        """
        model = self.code_model if query_type == "code" else self.general_model

        try:
            result = self.client.embed(
                texts=[query],
                model=model,
                input_type="query"  # Important for retrieval quality
            )

            self.total_tokens_used += result.total_tokens
            self.total_requests += 1

            return np.array(result.embeddings[0]), result.total_tokens

        except Exception as e:
            logger.error(f"Voyage API error (query): {e}")
            return np.zeros(1024), 0

    def get_usage_stats(self) -> dict:
        """Get usage statistics"""
        return {
            'total_tokens': self.total_tokens_used,
            'total_requests': self.total_requests,
            'remaining_free_tokens': max(0, 200_000_000 - self.total_tokens_used),
            'estimated_cost': 0.0 if self.total_tokens_used < 200_000_000 else (self.total_tokens_used - 200_000_000) * 0.00012 / 1000,
        }


class CohereEmbedder:
    """
    Cohere embedding client (placeholder for future)

    Could add support for:
    - embed-english-v3.0 (general purpose)
    """

    def __init__(self, api_key: str):
        self.api_key = api_key
        logger.warning("Cohere embedder not yet implemented")
        raise NotImplementedError("Cohere support coming soon")


class OpenAIEmbedder:
    """
    OpenAI embedding client (placeholder for future)

    Could add support for:
    - text-embedding-3-large (3072d, Matryoshka)
    - text-embedding-3-small (1536d)
    """

    def __init__(self, api_key: str):
        self.api_key = api_key
        logger.warning("OpenAI embedder not yet implemented")
        raise NotImplementedError("OpenAI support coming soon")