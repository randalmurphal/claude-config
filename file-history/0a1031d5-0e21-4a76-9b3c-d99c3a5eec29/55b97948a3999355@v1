"""
Hook integration for Claude Code PreToolUse and PostToolUse hooks.

Provides fast pattern retrieval for PreToolUse context injection
and async pattern detection for PostToolUse learning.

NO DEFAULTS - all configuration required.
"""

import logging
import asyncio
import json
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
from datetime import datetime

from prism_mcp.utils.config import get_config

logger = logging.getLogger(__name__)


class HookIntegration:
    """
    Integration layer for Claude Code hooks.

    Provides:
    - Fast pattern retrieval for PreToolUse context injection
    - Critical pattern blocking
    - Async pattern detection for PostToolUse learning
    - Auto-preference creation from high-confidence patterns

    NO DEFAULTS - crashes if configuration missing.
    """

    def __init__(self):
        """Initialize hook integration."""
        self.config = get_config()

        # Validate hook integration configuration
        if not hasattr(self.config, 'integrations') or not hasattr(self.config.integrations, 'hooks'):
            raise RuntimeError(
                "integrations.hooks configuration not found. "
                "Add integrations.hooks section to config.yaml"
            )

        hooks_config = self.config.integrations.hooks

        # Validate required configuration
        if not hasattr(hooks_config, 'enabled'):
            raise RuntimeError("integrations.hooks.enabled not configured")

        if not hooks_config.enabled:
            logger.info("Hook integration disabled in configuration")
            return

        # Get PreToolUse configuration
        self.pre_tool_config = getattr(hooks_config, 'pre_tool_use', None)
        if not self.pre_tool_config:
            raise RuntimeError("integrations.hooks.pre_tool_use not configured")

        self.retrieval_mode = getattr(self.pre_tool_config, 'retrieval_mode', None)
        self.timeout_ms = getattr(self.pre_tool_config, 'timeout_ms', None)
        self.block_on_critical = getattr(self.pre_tool_config, 'block_on_critical', None)
        self.inject_context = getattr(self.pre_tool_config, 'inject_context', None)

        if any(v is None for v in [self.retrieval_mode, self.timeout_ms, self.block_on_critical, self.inject_context]):
            raise RuntimeError(
                "pre_tool_use config incomplete: retrieval_mode, timeout_ms, "
                "block_on_critical, inject_context all required"
            )

        # Get PostToolUse configuration
        self.post_tool_config = getattr(hooks_config, 'post_tool_use', None)
        if not self.post_tool_config:
            raise RuntimeError("integrations.hooks.post_tool_use not configured")

        # Note: The Pydantic model uses async_ as the field name (with alias="async")
        self.async_processing = getattr(self.post_tool_config, 'async_', None)
        self.pattern_detection = getattr(self.post_tool_config, 'pattern_detection', None)
        self.auto_preference_threshold = getattr(self.post_tool_config, 'auto_preference_threshold', None)
        self.log_file = getattr(self.post_tool_config, 'log_file', None)

        if any(v is None for v in [self.async_processing, self.pattern_detection,
                                   self.auto_preference_threshold, self.log_file]):
            raise RuntimeError(
                "post_tool_use config incomplete: async, pattern_detection, "
                "auto_preference_threshold, log_file all required"
            )

        logger.info(
            f"HookIntegration: pre_mode={self.retrieval_mode}, "
            f"timeout={self.timeout_ms}ms, auto_threshold={self.auto_preference_threshold}"
        )

    async def handle_pre_tool_use(
        self,
        tool_name: str,
        file_path: Optional[str],
        session_id: str,
        additional_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Handle PreToolUse hook request.

        Args:
            tool_name: Name of tool being called
            file_path: File path (if applicable)
            session_id: Session ID
            additional_context: Additional context data

        Returns:
            {
                "should_block": bool,
                "block_reason": str | None,
                "context_patterns": [str],
                "critical_patterns": [str]
            }
        """
        try:
            # Only process code files
            if file_path and not self._is_code_file(file_path):
                return {
                    "should_block": False,
                    "block_reason": None,
                    "context_patterns": [],
                    "critical_patterns": []
                }

            # Build query for pattern retrieval
            query = self._build_pre_tool_query(tool_name, file_path, additional_context)

            # Fast pattern retrieval using lightning mode
            from prism_mcp.core.retrieval_coordinator import get_retrieval_coordinator
            coordinator = get_retrieval_coordinator()

            # Use timeout for lightning mode
            timeout_seconds = self.timeout_ms / 1000.0
            patterns = await asyncio.wait_for(
                coordinator.retrieve_intelligent(
                    query=query,
                    session_id=session_id,
                    retrieval_mode=self.retrieval_mode,
                    limit=5  # Keep it fast
                ),
                timeout=timeout_seconds
            )

            # Extract pattern content
            context_patterns = []
            critical_patterns = []

            for memory, scores in patterns:
                content = memory.content

                # Check if pattern is critical
                if self._is_critical_pattern(content):
                    critical_patterns.append(content)
                else:
                    context_patterns.append(content)

            # Determine if should block
            should_block = False
            block_reason = None

            if self.block_on_critical and critical_patterns:
                should_block = True
                block_reason = f"Critical patterns detected: {len(critical_patterns)} pattern(s)"

            logger.debug(
                f"PreToolUse: tool={tool_name}, patterns={len(context_patterns)}, "
                f"critical={len(critical_patterns)}, block={should_block}"
            )

            return {
                "should_block": should_block,
                "block_reason": block_reason,
                "context_patterns": context_patterns,
                "critical_patterns": critical_patterns
            }

        except asyncio.TimeoutError:
            logger.warning(f"PreToolUse timeout after {timeout_seconds}s")
            return {
                "should_block": False,
                "block_reason": None,
                "context_patterns": [],
                "critical_patterns": []
            }
        except Exception as e:
            logger.error(f"PreToolUse failed: {e}")
            return {
                "should_block": False,
                "block_reason": None,
                "context_patterns": [],
                "critical_patterns": []
            }

    async def handle_post_tool_use(
        self,
        tool_name: str,
        file_path: Optional[str],
        session_id: str,
        file_content: Optional[str] = None,
        additional_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Handle PostToolUse hook request.

        Args:
            tool_name: Name of tool that was called
            file_path: File path (if applicable)
            session_id: Session ID
            file_content: Content of the file (if available)
            additional_context: Additional context data

        Returns:
            {
                "patterns_detected": int,
                "preferences_created": int,
                "async_task_id": str | None
            }
        """
        try:
            # Only process code tools
            if not self._is_code_tool(tool_name):
                return {
                    "patterns_detected": 0,
                    "preferences_created": 0,
                    "async_task_id": None
                }

            if self.async_processing:
                # Start async pattern detection
                task_id = f"post_hook_{session_id}_{datetime.now().timestamp()}"

                # Schedule async task
                asyncio.create_task(
                    self._async_pattern_detection(
                        task_id, tool_name, file_path, session_id,
                        file_content, additional_context
                    )
                )

                return {
                    "patterns_detected": 0,
                    "preferences_created": 0,
                    "async_task_id": task_id
                }
            else:
                # Synchronous pattern detection
                result = await self._detect_and_create_preferences(
                    tool_name, file_path, session_id, file_content, additional_context
                )

                return {
                    "patterns_detected": result.get("patterns_detected", 0),
                    "preferences_created": result.get("preferences_created", 0),
                    "async_task_id": None
                }

        except Exception as e:
            logger.error(f"PostToolUse failed: {e}")
            return {
                "patterns_detected": 0,
                "preferences_created": 0,
                "async_task_id": None
            }

    async def _async_pattern_detection(
        self,
        task_id: str,
        tool_name: str,
        file_path: Optional[str],
        session_id: str,
        file_content: Optional[str],
        additional_context: Optional[Dict[str, Any]]
    ):
        """Async pattern detection and preference creation."""
        try:
            result = await self._detect_and_create_preferences(
                tool_name, file_path, session_id, file_content, additional_context
            )

            # Log result
            await self._log_hook_detection(task_id, result)

            logger.debug(
                f"Async pattern detection complete: task={task_id}, "
                f"patterns={result.get('patterns_detected', 0)}, "
                f"preferences={result.get('preferences_created', 0)}"
            )

        except Exception as e:
            logger.error(f"Async pattern detection failed: task={task_id}, error={e}")
            await self._log_hook_detection(task_id, {"error": str(e)})

    async def _detect_and_create_preferences(
        self,
        tool_name: str,
        file_path: Optional[str],
        session_id: str,
        file_content: Optional[str],
        additional_context: Optional[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Detect patterns and create preferences from tool usage."""
        patterns_detected = 0
        preferences_created = 0

        try:
            if not file_content or not file_path:
                return {"patterns_detected": 0, "preferences_created": 0}

            # Detect language
            language = self._detect_language(file_path)

            # Pattern detection
            from prism_mcp.core.pattern_engine import get_pattern_engine
            pattern_engine = get_pattern_engine()

            patterns = await pattern_engine.detect_patterns(
                code=file_content,
                language=language,
                instruction=f"Analyze patterns from {tool_name} on {file_path}"
            )

            patterns_detected = len(patterns)

            # Create preferences from high-confidence patterns
            if self.pattern_detection:
                from prism_mcp.core.preference_manager import get_preference_manager
                pref_manager = get_preference_manager()

                for pattern in patterns:
                    confidence = pattern.get('confidence', 0.0)

                    if confidence >= self.auto_preference_threshold:
                        try:
                            result = await pref_manager.suggest_preference(
                                content=pattern.get('description', ''),
                                category='pattern',
                                confidence=confidence,
                                detection_method='hook_detection',
                                evidence=f"Detected via {tool_name} hook on {file_path}",
                                session_id=session_id
                            )

                            if result and 'preference_id' in result:
                                # Auto-approve high confidence patterns
                                if confidence >= 0.85:
                                    await pref_manager.approve_preference(
                                        result['preference_id'],
                                        session_id=session_id,
                                        notes=f"Auto-approved from hook detection (confidence: {confidence})"
                                    )

                                preferences_created += 1

                        except Exception as e:
                            logger.warning(f"Failed to create preference from pattern: {e}")

            return {
                "patterns_detected": patterns_detected,
                "preferences_created": preferences_created
            }

        except Exception as e:
            logger.error(f"Pattern detection and preference creation failed: {e}")
            return {"patterns_detected": 0, "preferences_created": 0}

    def _build_pre_tool_query(
        self,
        tool_name: str,
        file_path: Optional[str],
        additional_context: Optional[Dict[str, Any]]
    ) -> str:
        """Build query for pattern retrieval."""
        query_parts = [f"patterns for {tool_name}"]

        if file_path:
            file_type = Path(file_path).suffix
            query_parts.append(f"{file_type} files")

        if additional_context:
            for key, value in additional_context.items():
                if isinstance(value, str) and len(value) < 50:
                    query_parts.append(f"{key}: {value}")

        return " ".join(query_parts)

    def _is_code_file(self, file_path: str) -> bool:
        """Check if file is a code file."""
        code_extensions = {'.py', '.js', '.ts', '.tsx', '.go', '.rs', '.java', '.cpp', '.c', '.h'}
        return Path(file_path).suffix.lower() in code_extensions

    def _is_code_tool(self, tool_name: str) -> bool:
        """Check if tool is a code modification tool."""
        code_tools = {'Write', 'Edit', 'MultiEdit', 'NotebookEdit'}
        return tool_name in code_tools

    def _is_critical_pattern(self, content: str) -> bool:
        """Check if pattern is critical (should block execution)."""
        critical_keywords = ['CRITICAL', 'SECURITY', 'DANGER', 'NEVER', 'FORBIDDEN']
        content_upper = content.upper()
        return any(keyword in content_upper for keyword in critical_keywords)

    def _detect_language(self, file_path: str) -> str:
        """Detect programming language from file extension."""
        extension_map = {
            '.py': 'python',
            '.js': 'javascript',
            '.ts': 'typescript',
            '.tsx': 'typescript',
            '.go': 'go',
            '.rs': 'rust',
            '.java': 'java',
            '.cpp': 'cpp',
            '.c': 'c',
            '.h': 'c'
        }

        extension = Path(file_path).suffix.lower()
        return extension_map.get(extension, 'python')

    async def _log_hook_detection(self, task_id: str, result: Dict[str, Any]):
        """Log hook detection result."""
        try:
            # Resolve log file path
            log_path = Path(self.log_file).expanduser()
            log_path.parent.mkdir(parents=True, exist_ok=True)

            # Create log entry
            log_entry = {
                "timestamp": datetime.now().isoformat(),
                "task_id": task_id,
                "result": result
            }

            # Append to log file
            with open(log_path, 'a', encoding='utf-8') as f:
                f.write(json.dumps(log_entry) + '\n')

        except Exception as e:
            logger.warning(f"Failed to log hook detection: {e}")

    def get_hook_scripts(self) -> Dict[str, str]:
        """
        Get hook script templates for Claude Code installation.

        Returns:
            Dict mapping script names to their content
        """
        return {
            "pre-tool-use.sh": self._get_pre_tool_script(),
            "post-tool-use.sh": self._get_post_tool_script()
        }

    def _get_pre_tool_script(self) -> str:
        """Generate PreToolUse hook script."""
        # Get API configuration - use external port for hook scripts
        api_host = self.config.server.http_host
        api_port = getattr(self.config.server, 'external_port', self.config.server.http_port)

        return f'''#!/bin/bash
# PreToolUse hook for PRISM integration
# Auto-generated by PRISM Phase 4B implementation

TOOL_NAME="$1"
FILE_PATH="$2"
SESSION_ID="$3"

# Only for code files
[[ ! "$FILE_PATH" =~ \\.(py|js|ts|tsx|go|rs|java|cpp|c|h)$ ]] && exit 0

# Query PRISM (lightning mode, <{self.timeout_ms}ms)
RESULT=$(curl -s -m {self.timeout_ms / 1000.0} -X POST http://{api_host}:{api_port}/api/hooks/pre-tool-use \\
    -H "Content-Type: application/json" \\
    -H "Authorization: Bearer {self.config.server.api_key}" \\
    -d "{{
        \\"tool_name\\": \\"$TOOL_NAME\\",
        \\"file_path\\": \\"$FILE_PATH\\",
        \\"session_id\\": \\"$SESSION_ID\\"
    }}" 2>/dev/null)

# Parse response
SHOULD_BLOCK=$(echo "$RESULT" | jq -r '.should_block // false' 2>/dev/null)
BLOCK_REASON=$(echo "$RESULT" | jq -r '.block_reason // ""' 2>/dev/null)
PATTERNS=$(echo "$RESULT" | jq -r '.context_patterns[]? // ""' 2>/dev/null)

# Block if critical pattern
if [ "$SHOULD_BLOCK" = "true" ]; then
    echo "BLOCK: $BLOCK_REASON"
    if [ -n "$PATTERNS" ]; then
        echo "Critical patterns:"
        echo "$PATTERNS"
    fi
    exit 1
fi

# Inject patterns as context
if [ -n "$PATTERNS" ]; then
    echo "CONTEXT: Relevant patterns:"
    echo "$PATTERNS"
fi
'''

    def _get_post_tool_script(self) -> str:
        """Generate PostToolUse hook script."""
        # Get API configuration - use external port for hook scripts
        api_host = self.config.server.http_host
        api_port = getattr(self.config.server, 'external_port', self.config.server.http_port)

        return f'''#!/bin/bash
# PostToolUse hook for PRISM integration
# Auto-generated by PRISM Phase 4B implementation

TOOL_NAME="$1"
FILE_PATH="$2"
SESSION_ID="$3"

# Only for code tools
[[ ! "$TOOL_NAME" =~ ^(Write|Edit|MultiEdit|NotebookEdit)$ ]] && exit 0

# Read file content
CODE=$(cat "$FILE_PATH" 2>/dev/null) || exit 0

# Pattern detection (async)
(
    curl -s -X POST http://{api_host}:{api_port}/api/hooks/post-tool-use \\
        -H "Content-Type: application/json" \\
        -H "Authorization: Bearer {self.config.server.api_key}" \\
        -d "{{
            \\"tool_name\\": \\"$TOOL_NAME\\",
            \\"file_path\\": \\"$FILE_PATH\\",
            \\"session_id\\": \\"$SESSION_ID\\",
            \\"file_content\\": $(echo "$CODE" | jq -Rs .)
        }}" \\
        >> {self.log_file} 2>&1
) &
'''