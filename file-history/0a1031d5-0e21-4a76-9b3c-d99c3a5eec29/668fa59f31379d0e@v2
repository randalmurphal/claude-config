"""
Qdrant vector database manager.

Direct usage of Qdrant client - NO abstractions.
NO DEFAULTS, NO FALLBACKS.
"""

import logging
import time
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
import numpy as np

from qdrant_client import QdrantClient
from qdrant_client.http.exceptions import ResponseHandlingException, UnexpectedResponse
from qdrant_client.models import (
    Distance,
    VectorParams,
    PointStruct,
    Filter,
    FieldCondition,
    MatchValue,
    SearchRequest,
    UpdateStatus
)

from prism_mcp.utils.config import get_config

logger = logging.getLogger(__name__)

# Dual-collection constants for Phase 1
COLLECTION_E5 = "memories_e5"
COLLECTION_STARCODER = "memories_starcoder"
E5_DIMENSION = 4096
STARCODER_DIMENSION = 4608

# Memory type to collection mapping
MEMORY_TYPE_TO_COLLECTION = {
    # Research notes → E5
    "research_note": COLLECTION_E5,
    "decision": COLLECTION_E5,
    "gotcha": COLLECTION_E5,
    "guidance": COLLECTION_E5,
    # General memory types → E5
    "pattern": COLLECTION_E5,
    "correction": COLLECTION_E5,
    "preference": COLLECTION_E5,
    "discovery": COLLECTION_E5,
    "session_start": COLLECTION_E5,
    "user_preference": COLLECTION_E5,
    # Code patterns → StarCoder2
    "code_pattern": COLLECTION_STARCODER,
    "extracted_pattern": COLLECTION_STARCODER,
    "ast_pattern": COLLECTION_STARCODER,
    # Code symbols → StarCoder2
    "code_function": COLLECTION_STARCODER,
    "code_class": COLLECTION_STARCODER,
    "code_method": COLLECTION_STARCODER,
    "code_variable": COLLECTION_STARCODER,
}


@dataclass
class VectorPoint:
    """A point in vector space with metadata."""
    point_id: str
    vector: np.ndarray
    payload: Dict[str, Any]


class QdrantManager:
    """
    Direct Qdrant operations - NO WRAPPERS.

    Single responsibility: Vector storage and retrieval.
    """

    def __init__(self):
        """
        Initialize Qdrant client from configuration with retry logic.

        Raises:
            RuntimeError: If configuration missing or connection fails after retries
        """
        config = get_config()

        # Retry configuration for container startup
        max_retries = 10
        retry_delay = 2  # seconds

        last_error = None
        for attempt in range(max_retries):
            try:
                # Connect to Qdrant - NO DEFAULTS
                self.client = QdrantClient(url=config.database.qdrant_url)

                # Verify connection by getting collections
                collections = self.client.get_collections()
                logger.info(f"Connected to Qdrant with {len(collections.collections)} collections")
                logger.info(f"Dual-collection mode: {COLLECTION_E5} ({E5_DIMENSION}), {COLLECTION_STARCODER} ({STARCODER_DIMENSION})")
                return  # Success!

            except (ResponseHandlingException, UnexpectedResponse, ConnectionError, OSError) as e:
                last_error = e
                if attempt < max_retries - 1:
                    wait_time = retry_delay * (2 ** attempt)  # Exponential backoff
                    logger.warning(f"Qdrant connection attempt {attempt + 1}/{max_retries} failed: {e}. Retrying in {wait_time}s...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"Qdrant connection failed after {max_retries} attempts")
                    raise RuntimeError(f"Failed to connect to Qdrant at {config.database.qdrant_url} after {max_retries} attempts: {last_error}") from last_error

    @staticmethod
    def get_collection_for_memory_type(memory_type: str) -> str:
        """
        Map memory type to Qdrant collection name.

        Args:
            memory_type: Type of memory (research_note, code_pattern, etc.)

        Returns:
            Collection name (memories_e5 or memories_starcoder)

        Raises:
            RuntimeError: If memory_type unknown (NO DEFAULTS)
        """
        collection = MEMORY_TYPE_TO_COLLECTION.get(memory_type)

        if not collection:
            raise RuntimeError(
                f"Unknown memory_type '{memory_type}'. "
                f"Valid types: {list(MEMORY_TYPE_TO_COLLECTION.keys())}"
            )

        return collection

    def create_dual_collections(self, distance: Distance = Distance.COSINE):
        """
        Create both E5 and StarCoder2 collections with correct dimensions.

        This is the primary method for Phase 1 dual-collection setup.

        Args:
            distance: Distance metric (default: COSINE)

        Raises:
            RuntimeError: If creation fails
        """
        logger.info("Creating dual collections for Phase 1...")

        # Create E5 collection (4096 dims)
        self.ensure_collection_with_dimension(
            collection_name=COLLECTION_E5,
            dimension=E5_DIMENSION,
            distance=distance
        )
        logger.info(f"✓ {COLLECTION_E5} ready ({E5_DIMENSION} dims)")

        # Create StarCoder2 collection (4608 dims)
        self.ensure_collection_with_dimension(
            collection_name=COLLECTION_STARCODER,
            dimension=STARCODER_DIMENSION,
            distance=distance
        )
        logger.info(f"✓ {COLLECTION_STARCODER} ready ({STARCODER_DIMENSION} dims)")

        logger.info("✓ Dual collections created successfully")

    def ensure_collection_with_dimension(
        self,
        collection_name: str,
        dimension: int,
        distance: Distance = Distance.COSINE
    ):
        """
        Ensure collection exists with specified dimension.

        Unlike ensure_collection(), this uses explicit dimension parameter
        instead of embedder dimension.

        Args:
            collection_name: Collection name
            dimension: Vector dimension
            distance: Distance metric

        Note: Will DELETE and recreate if dimensions don't match!
        """
        collections = self.client.get_collections().collections
        exists = any(c.name == collection_name for c in collections)

        if exists:
            # Check dimensions match
            collection_info = self.client.get_collection(collection_name)
            current_dim = collection_info.config.params.vectors.size

            if current_dim != dimension:
                logger.warning(
                    f"Collection {collection_name} has wrong dimension "
                    f"({current_dim} vs {dimension}). Deleting and recreating."
                )
                self.client.delete_collection(collection_name)
                exists = False
            else:
                logger.info(f"Collection {collection_name} exists with correct dimensions")
                return

        if not exists:
            logger.info(f"Creating collection {collection_name} with dimension {dimension}")
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(
                    size=dimension,
                    distance=distance
                )
            )

    def ensure_collection(
        self,
        collection_name: str,
        distance: Distance = Distance.COSINE
    ):
        """
        Ensure collection exists with correct configuration.

        Args:
            collection_name: Name of collection
            distance: Distance metric to use

        Note: Will DELETE and recreate if dimensions don't match!
        Note: Collection dimension is auto-detected from collection name
        """
        # Determine dimension from collection name
        if collection_name == COLLECTION_E5:
            expected_dim = E5_DIMENSION
        elif collection_name == COLLECTION_STARCODER:
            expected_dim = STARCODER_DIMENSION
        elif collection_name == "memories":
            # Legacy collection name - assume E5 dimension
            expected_dim = E5_DIMENSION
        else:
            # For other collections (code_patterns, etc.), use StarCoder2 dimension
            expected_dim = STARCODER_DIMENSION

        collections = self.client.get_collections().collections
        exists = any(c.name == collection_name for c in collections)

        if exists:
            # Check dimensions match
            collection_info = self.client.get_collection(collection_name)
            current_dim = collection_info.config.params.vectors.size

            if current_dim != expected_dim:
                logger.warning(
                    f"Collection {collection_name} has wrong dimension "
                    f"({current_dim} vs {expected_dim}). Deleting and recreating."
                )
                self.client.delete_collection(collection_name)
                exists = False
            else:
                logger.info(f"Collection {collection_name} exists with correct dimensions")
                return

        if not exists:
            logger.info(f"Creating collection {collection_name} with dimension {expected_dim}")
            self.client.create_collection(
                collection_name=collection_name,
                vectors_config=VectorParams(
                    size=expected_dim,
                    distance=distance
                )
            )

    def upsert(
        self,
        collection_name: str,
        points: List[VectorPoint]
    ) -> UpdateStatus:
        """
        Insert or update points in collection.

        Args:
            collection_name: Collection to update
            points: Points to upsert

        Returns:
            Update status from Qdrant
        """
        # Convert to Qdrant format
        qdrant_points = [
            PointStruct(
                id=self._convert_id(point.point_id),
                vector=point.vector.tolist(),
                payload=point.payload
            )
            for point in points
        ]

        result = self.client.upsert(
            collection_name=collection_name,
            points=qdrant_points
        )

        logger.info(f"Upserted {len(points)} points to {collection_name}")

        return result

    def search(
        self,
        collection_name: str,
        query_vector: np.ndarray,
        limit: int,
        score_threshold: Optional[float] = None,
        filter_conditions: Optional[Dict[str, Any]] = None,
        filter_exclude: Optional[Dict[str, Any]] = None,
        with_payload: bool = True,
        with_vectors: bool = False
    ) -> List[Dict[str, Any]]:
        """
        Search for similar vectors.

        Args:
            collection_name: Collection to search
            query_vector: Query embedding
            limit: Maximum results
            score_threshold: Minimum similarity score
            filter_conditions: Payload filters (must match)
            filter_exclude: Payload filters (must not match)
            with_payload: Include payload in results
            with_vectors: Include vectors in results

        Returns:
            List of search results with scores and payloads
        """
        # Build filter if conditions provided
        query_filter = None
        must_conditions = []
        must_not_conditions = []

        if filter_conditions:
            for field, value in filter_conditions.items():
                must_conditions.append(
                    FieldCondition(
                        key=field,
                        match=MatchValue(value=value)
                    )
                )

        if filter_exclude:
            for field, value in filter_exclude.items():
                must_not_conditions.append(
                    FieldCondition(
                        key=field,
                        match=MatchValue(value=value)
                    )
                )

        if must_conditions or must_not_conditions:
            query_filter = Filter(
                must=must_conditions if must_conditions else None,
                must_not=must_not_conditions if must_not_conditions else None
            )

        # Execute search
        results = self.client.search(
            collection_name=collection_name,
            query_vector=query_vector.tolist(),
            limit=limit,
            query_filter=query_filter,
            score_threshold=score_threshold,
            with_payload=with_payload,
            with_vectors=with_vectors
        )

        # Convert to standard format
        return [
            {
                "id": str(result.id),
                "score": result.score,
                "payload": result.payload,
                "vector": result.vector if with_vectors and hasattr(result, 'vector') else None
            }
            for result in results
        ]

    def get_by_id(
        self,
        collection_name: str,
        point_id: str
    ) -> Optional[Dict[str, Any]]:
        """
        Get a specific point by ID.

        Args:
            collection_name: Collection name
            point_id: Point ID

        Returns:
            Point data or None if not found
        """
        converted_id = self._convert_id(point_id)

        points = self.client.retrieve(
            collection_name=collection_name,
            ids=[converted_id]
        )

        if not points:
            return None

        point = points[0]
        return {
            "id": str(point.id),
            "vector": point.vector,
            "payload": point.payload
        }

    def delete(
        self,
        collection_name: str,
        point_ids: List[str]
    ) -> UpdateStatus:
        """
        Delete points from collection.

        Args:
            collection_name: Collection name
            point_ids: IDs to delete

        Returns:
            Update status
        """
        converted_ids = [self._convert_id(pid) for pid in point_ids]

        result = self.client.delete(
            collection_name=collection_name,
            points_selector=converted_ids
        )

        logger.info(f"Deleted {len(point_ids)} points from {collection_name}")

        return result

    def count(
        self,
        collection_name: str,
        filter_conditions: Optional[Dict[str, Any]] = None
    ) -> int:
        """
        Count points in collection.

        Args:
            collection_name: Collection name
            filter_conditions: Optional filters

        Returns:
            Point count
        """
        if filter_conditions:
            # Count with filter requires search with limit=0
            # This is a Qdrant limitation
            conditions = []
            for field, value in filter_conditions.items():
                conditions.append(
                    FieldCondition(
                        key=field,
                        match=MatchValue(value=value)
                    )
                )

            query_filter = Filter(must=conditions)

            # Use scroll to count (more efficient than search)
            result = self.client.scroll(
                collection_name=collection_name,
                scroll_filter=query_filter,
                limit=1  # Just need count
            )

            # Get total from result
            # Note: This is approximate for large filtered counts
            return len(result[0])  # This isn't ideal but Qdrant doesn't have filtered count

        # Simple count without filter
        collection_info = self.client.get_collection(collection_name)
        return collection_info.points_count

    def _convert_id(self, point_id: str):
        """
        Convert string ID to appropriate format for Qdrant.

        Qdrant requires integer or UUID IDs.
        - UUID strings (36-char with hyphens): Pass through as-is
        - Other strings (12-char hex, etc.): Convert to integer via MD5

        Args:
            point_id: String ID

        Returns:
            UUID string (for 36-char UUIDs) or integer (for other IDs)
        """
        import hashlib

        # Check if it's a valid UUID string format (36 chars with hyphens)
        if len(point_id) == 36 and point_id.count('-') == 4:
            # Validate UUID format: 8-4-4-4-12
            parts = point_id.split('-')
            if (len(parts) == 5 and
                len(parts[0]) == 8 and len(parts[1]) == 4 and
                len(parts[2]) == 4 and len(parts[3]) == 4 and len(parts[4]) == 12):
                # Valid UUID string - Qdrant accepts these natively
                return point_id

        # Non-UUID string: Convert to integer via MD5
        hash_bytes = hashlib.md5(point_id.encode()).digest()[:8]
        return int.from_bytes(hash_bytes, byteorder='big') & 0x7FFFFFFFFFFFFFFF  # Ensure positive

    def get_collection_info(self, collection_name: str) -> Dict[str, Any]:
        """
        Get collection statistics and configuration.

        Args:
            collection_name: Collection name

        Returns:
            Collection information
        """
        info = self.client.get_collection(collection_name)

        return {
            "points_count": info.points_count,
            "vector_size": info.config.params.vectors.size,
            "distance": info.config.params.vectors.distance,
            "status": info.status
        }

    def store_pattern(
        self,
        pattern_id: str,
        pattern_name: str,
        pattern_type: str,
        embedding: np.ndarray,
        metadata: Dict[str, Any]
    ):
        """
        Store a pattern in the code_patterns collection.

        Args:
            pattern_id: Unique pattern identifier
            pattern_name: Human-readable pattern name
            pattern_type: Type of pattern (anti_pattern, security_issue, etc.)
            embedding: Pattern embedding vector
            metadata: Additional pattern metadata

        Raises:
            RuntimeError: If storage fails
        """
        # Ensure code_patterns collection exists (matching everywhere else)
        self.ensure_collection("code_patterns")

        # Prepare payload with all pattern data
        payload = {
            "pattern_id": pattern_id,  # Include pattern_id in payload for searches
            "name": pattern_name,  # Use 'name' to match existing patterns
            "pattern_type": pattern_type,
            **metadata
        }

        # Create vector point
        point = VectorPoint(
            point_id=pattern_id,
            vector=embedding,
            payload=payload
        )

        # Store in Qdrant - use code_patterns to match rest of system
        self.upsert("code_patterns", [point])

        logger.info(f"Stored pattern {pattern_name} ({pattern_id})")

    def load_all_patterns(self) -> List[Dict[str, Any]]:
        """
        Load all patterns from the patterns collection.

        Returns:
            List of patterns with their data

        Raises:
            RuntimeError: If loading fails
        """
        # Ensure collection exists
        self.ensure_collection("patterns")

        # Scroll through all patterns
        results, _ = self.client.scroll(
            collection_name="patterns",
            limit=10000  # Load up to 10k patterns
        )

        patterns = []
        for point in results:
            pattern_data = {
                "pattern_id": str(point.id),
                "embedding": np.array(point.vector) if point.vector else None,
                **point.payload
            }
            patterns.append(pattern_data)

        logger.info(f"Loaded {len(patterns)} patterns from Qdrant")

        return patterns

    def delete_pattern(self, pattern_id: str):
        """
        Delete a pattern from storage.

        Args:
            pattern_id: Pattern to delete
        """
        self.delete("patterns", [pattern_id])
        logger.info(f"Deleted pattern {pattern_id}")


def get_qdrant_manager() -> QdrantManager:
    """Get QdrantManager instance with config."""
    return QdrantManager()