#!/usr/bin/env python3
"""
Compare Voyage API embeddings vs Local models

Tests both:
- voyage-code-3 vs StarCoder2-7B (for code patterns)
- voyage-3-large vs E5-Mistral-7B (for semantic queries)

Measures:
- Retrieval quality (precision, recall)
- Latency (local vs API)
- Cost estimation

Usage:
    # Set API keys as env vars
    export VOYAGE_API_KEY="pa-xxxx"

    # Run comparison
    python test_voyage_vs_local.py
"""

import os
import sys
import time
import json
from pathlib import Path
from typing import List, Dict, Tuple
from dataclasses import dataclass, asdict

# Add parent directories to path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

import numpy as np
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, VectorParams


@dataclass
class TestResult:
    """Results from a single test query"""
    query: str
    query_type: str  # 'code' or 'semantic'

    # Local results
    local_top5: List[str]
    local_scores: List[float]
    local_latency_ms: float

    # API results
    api_top5: List[str]
    api_scores: List[float]
    api_latency_ms: float
    api_tokens: int
    api_cost: float

    # Comparison
    overlap_count: int
    precision_improvement: float
    latency_ratio: float


class VoyageEmbedder:
    """Voyage AI API client"""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.voyageai.com/v1"

        # Lazy import
        try:
            import voyageai
            self.client = voyageai.Client(api_key=api_key)
        except ImportError:
            print("⚠️  voyageai package not installed. Run: pip install voyageai")
            sys.exit(1)

    def embed_code(self, texts: List[str]) -> Tuple[np.ndarray, int]:
        """
        Embed code using voyage-code-3

        Returns:
            (embeddings, token_count)
        """
        result = self.client.embed(
            texts=texts,
            model="voyage-code-3",
            input_type="document"  # or "query" for queries
        )

        embeddings = np.array(result.embeddings)
        tokens = result.total_tokens

        return embeddings, tokens

    def embed_semantic(self, texts: List[str]) -> Tuple[np.ndarray, int]:
        """
        Embed semantic text using voyage-3-large

        Returns:
            (embeddings, token_count)
        """
        result = self.client.embed(
            texts=texts,
            model="voyage-3-large",
            input_type="document"
        )

        embeddings = np.array(result.embeddings)
        tokens = result.total_tokens

        return embeddings, tokens


class LocalEmbedder:
    """Local E5-Mistral + StarCoder2 embedder"""

    def __init__(self):
        from prism_mcp.models.embedder import PrismEmbedder
        from prism_mcp.utils.config import Config

        # Load config
        config_path = Path(__file__).parent.parent.parent / "config" / "config.yaml"
        self.config = Config.from_yaml(config_path)

        # Initialize embedder
        print("Loading local models (E5-Mistral + StarCoder2)...")
        self.embedder = PrismEmbedder(config=self.config)
        print("✓ Local models loaded")

    def embed_code(self, texts: List[str]) -> np.ndarray:
        """Embed code using StarCoder2"""
        embeddings = []
        for text in texts:
            emb = self.embedder.embed_code(text)
            embeddings.append(emb)
        return np.array(embeddings)

    def embed_semantic(self, texts: List[str]) -> np.ndarray:
        """Embed semantic text using E5-Mistral"""
        embeddings = []
        for text in texts:
            emb = self.embedder.embed_text(text)
            embeddings.append(emb)
        return np.array(embeddings)


# Test queries
CODE_QUERIES = [
    "JWT authentication with refresh tokens",
    "async database connection pooling",
    "error handling in REST API endpoints",
    "rate limiting middleware implementation",
    "OAuth2 authorization code flow",
]

SEMANTIC_QUERIES = [
    "best practices for authentication security",
    "how to handle database connection failures",
    "API error response formatting standards",
    "preventing API abuse and rate limit strategies",
    "secure token storage and rotation",
]

# Sample patterns (we'll retrieve these from Qdrant)
def get_sample_patterns(qdrant_client: QdrantClient, limit: int = 100) -> List[Dict]:
    """Get sample patterns from existing Qdrant collection"""
    try:
        # Try to get from code_patterns collection
        results = qdrant_client.scroll(
            collection_name="code_patterns",
            limit=limit,
        )

        patterns = []
        for point in results[0]:
            patterns.append({
                'id': str(point.id),
                'code': point.payload.get('code', ''),
                'description': point.payload.get('description', ''),
            })

        return patterns
    except Exception as e:
        print(f"⚠️  Could not load patterns from Qdrant: {e}")
        return []


def compare_retrievals(
    query: str,
    query_type: str,
    local_embedder: LocalEmbedder,
    voyage_embedder: VoyageEmbedder,
    patterns: List[Dict],
) -> TestResult:
    """
    Compare local vs API retrieval for a single query
    """

    # Get pattern embeddings
    pattern_texts = [p['description'] or p['code'][:500] for p in patterns]

    # === LOCAL EMBEDDING ===
    print(f"\n  Testing: {query}")
    print("  Local embedding...", end=" ", flush=True)
    local_start = time.time()

    if query_type == 'code':
        query_emb_local = local_embedder.embed_code([query])[0]
        pattern_embs_local = local_embedder.embed_code(pattern_texts)
    else:
        query_emb_local = local_embedder.embed_semantic([query])[0]
        pattern_embs_local = local_embedder.embed_semantic(pattern_texts)

    # Compute similarities
    similarities_local = np.dot(pattern_embs_local, query_emb_local)
    top5_idx_local = np.argsort(similarities_local)[-5:][::-1]

    local_latency = (time.time() - local_start) * 1000
    print(f"{local_latency:.0f}ms")

    # === API EMBEDDING ===
    print("  API embedding...", end=" ", flush=True)
    api_start = time.time()

    if query_type == 'code':
        query_emb_api, query_tokens = voyage_embedder.embed_code([query])
        pattern_embs_api, pattern_tokens = voyage_embedder.embed_code(pattern_texts)
        query_emb_api = query_emb_api[0]
    else:
        query_emb_api, query_tokens = voyage_embedder.embed_semantic([query])
        pattern_embs_api, pattern_tokens = voyage_embedder.embed_semantic(pattern_texts)
        query_emb_api = query_emb_api[0]

    # Compute similarities
    similarities_api = np.dot(pattern_embs_api, query_emb_api)
    top5_idx_api = np.argsort(similarities_api)[-5:][::-1]

    api_latency = (time.time() - api_start) * 1000
    total_tokens = query_tokens + pattern_tokens

    # Cost estimation (first 200M tokens free)
    api_cost = 0.0  # Free tier

    print(f"{api_latency:.0f}ms ({total_tokens:,} tokens)")

    # === COMPARISON ===
    local_top5 = [patterns[i]['id'] for i in top5_idx_local]
    api_top5 = [patterns[i]['id'] for i in top5_idx_api]

    overlap = set(local_top5) & set(api_top5)
    overlap_count = len(overlap)

    # Precision improvement (higher API scores = better)
    avg_score_local = similarities_local[top5_idx_local].mean()
    avg_score_api = similarities_api[top5_idx_api].mean()
    precision_improvement = (avg_score_api - avg_score_local) / avg_score_local * 100

    latency_ratio = api_latency / local_latency

    return TestResult(
        query=query,
        query_type=query_type,
        local_top5=local_top5,
        local_scores=similarities_local[top5_idx_local].tolist(),
        local_latency_ms=local_latency,
        api_top5=api_top5,
        api_scores=similarities_api[top5_idx_api].tolist(),
        api_latency_ms=api_latency,
        api_tokens=total_tokens,
        api_cost=api_cost,
        overlap_count=overlap_count,
        precision_improvement=precision_improvement,
        latency_ratio=latency_ratio,
    )


def print_summary(results: List[TestResult]):
    """Print summary statistics"""

    print("\n" + "="*80)
    print("SUMMARY")
    print("="*80)

    code_results = [r for r in results if r.query_type == 'code']
    semantic_results = [r for r in results if r.query_type == 'semantic']

    for category, cat_results in [("CODE", code_results), ("SEMANTIC", semantic_results)]:
        print(f"\n{category} QUERIES:")

        avg_overlap = np.mean([r.overlap_count for r in cat_results])
        avg_precision_improvement = np.mean([r.precision_improvement for r in cat_results])
        avg_latency_local = np.mean([r.local_latency_ms for r in cat_results])
        avg_latency_api = np.mean([r.api_latency_ms for r in cat_results])
        total_tokens = sum([r.api_tokens for r in cat_results])

        print(f"  Average overlap: {avg_overlap:.1f}/5 patterns")
        print(f"  Precision improvement: {avg_precision_improvement:+.1f}%")
        print(f"  Latency: Local {avg_latency_local:.0f}ms vs API {avg_latency_api:.0f}ms")
        print(f"  Total tokens: {total_tokens:,}")
        print(f"  Cost: FREE (within 200M token limit)")

    print("\n" + "="*80)
    print("RECOMMENDATION")
    print("="*80)

    avg_precision = np.mean([r.precision_improvement for r in results])

    if avg_precision > 10:
        print("✅ API embeddings show significant improvement (+10% precision)")
        print("   Recommend: Implement Tier 0 (PREMIUM_API)")
    elif avg_precision > 5:
        print("✅ API embeddings show moderate improvement (+5-10% precision)")
        print("   Recommend: Implement Tier 0 for better quality at zero cost")
    else:
        print("⚠️  API embeddings show minimal improvement")
        print("   Consider: Stick with local models for lower latency")


def main():
    """Run comparison tests"""

    print("="*80)
    print("VOYAGE API vs LOCAL MODELS COMPARISON")
    print("="*80)

    # Check for API key
    api_key = os.getenv("VOYAGE_API_KEY")
    if not api_key:
        print("\n⚠️  VOYAGE_API_KEY not set!")
        print("\nTo get your API key:")
        print("1. Go to: https://www.voyageai.com/")
        print("2. Sign up (free account)")
        print("3. Get API key from dashboard")
        print("4. Set env var: export VOYAGE_API_KEY='pa-xxxx'")
        print("\nThen run this script again.")
        sys.exit(1)

    # Initialize embedders
    print("\n1. Initializing embedders...")
    local_embedder = LocalEmbedder()
    voyage_embedder = VoyageEmbedder(api_key)
    print("✓ Both embedders ready")

    # Get sample patterns
    print("\n2. Loading sample patterns from Qdrant...")
    qdrant = QdrantClient(url="http://localhost:6333")
    patterns = get_sample_patterns(qdrant, limit=100)

    if not patterns:
        print("⚠️  No patterns found in Qdrant. Using synthetic patterns...")
        # Create some synthetic patterns for testing
        patterns = [
            {'id': f'test_{i}', 'code': f'def example_{i}(): pass', 'description': f'Example pattern {i}'}
            for i in range(100)
        ]
    else:
        print(f"✓ Loaded {len(patterns)} patterns")

    # Run tests
    print("\n3. Running comparison tests...")
    results = []

    print("\nCODE QUERIES:")
    for query in CODE_QUERIES:
        result = compare_retrievals(query, 'code', local_embedder, voyage_embedder, patterns)
        results.append(result)

    print("\nSEMANTIC QUERIES:")
    for query in SEMANTIC_QUERIES:
        result = compare_retrievals(query, 'semantic', local_embedder, voyage_embedder, patterns)
        results.append(result)

    # Print summary
    print_summary(results)

    # Save detailed results
    output_file = Path(__file__).parent / "comparison_results.json"
    with open(output_file, 'w') as f:
        json.dump([asdict(r) for r in results], f, indent=2)
    print(f"\n✓ Detailed results saved to: {output_file}")


if __name__ == "__main__":
    main()