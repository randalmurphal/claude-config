# PRISM MCP - Intelligent AI Memory System

**P**attern **R**ecognition and **I**ntelligent **S**ystem **M**emory

Production-ready AI memory system with 6-stage intelligent retrieval, pattern detection, preference learning, and continuous learning from feedback.

## Key Features

### Intelligent Memory Retrieval
- **6-Stage Pipeline**: Semantic search → Graph expansion → Context filtering → Temporal ranking → Diversity selection → Utility scoring
- **Multi-Signal Scoring**: Combines semantic similarity, graph connectivity, temporal relevance, and learned utility
- **Feedback Loop**: Continuously learns which memories are actually useful for specific tasks
- **Context-Aware**: Filters by role, task type, project, branch, and git SHA

### Pattern Detection
- **Hybrid Detection**: Tree-sitter AST + semantic embeddings
- **Multi-Language**: Python, Go, JavaScript/TypeScript
- **Pattern Evolution**: Dynamic weighting based on usage and success rate
- **11,800+ Patterns**: Loaded from major repositories

### Memory Management
- **4-Tier System**: ANCHORS → LONGTERM → EPISODIC → WORKING
- **Auto-Promotion**: Based on access patterns and frustration signals
- **Graph Algorithms**: PageRank for importance, Louvain for clustering
- **Session Tracking**: Maintains context across agent sessions

### Code Indexing & Preferences
- **Project Indexing**: Extracts symbols, functions, classes from codebases
- **Incremental Updates**: Git diff-based re-indexing
- **Smart Context**: Automatic relevant code injection for tasks
- **Preference Memory**: Learns user preferences from interactions (explicit statements, interventions, rejections)
- **Code Grounding**: Links preferences to code examples for better context

## ⚠️ NO DEFAULTS Philosophy

This system **fails loudly** rather than degrading:
- All configuration values must be explicit
- No `.get(key, default)` - crashes if missing
- No try/except without re-raising
- FULL POWER or CRASH - no silent fallbacks

## Prerequisites

- **Python**: 3.13+
- **Containers**: nerdctl & containerd (Docker not supported)
- **Memory**: 16GB+ RAM recommended
- **GPU**: Optional, 16GB+ VRAM for optimal performance

## Installation

### 1. Start Database Services

```bash
cd ../nerdctl
nerdctl compose up -d
```

This starts:
- **Qdrant** (port 6333): Vector search
- **Neo4j** (ports 7474, 7687): Graph database with GDS
- **Redis** (port 6379): Session cache

### 2. Install Python Package

```bash
pip install -e .
```

### 3. Configure System

```bash
cp config/config.template.yaml config/config.yaml
```

Edit `config/config.yaml`:
- Set `neo4j_password` (default: "your_password_here")
- Set `api_key` for HTTP API authentication
- Adjust scoring weights if desired (must sum to 1.0)

### 4. Download Embedding Model

```bash
python -m prism_mcp.bootstrap.download_models
```

Auto-detects GPU and downloads appropriate model:
- **GPU (16GB+)**: all-MiniLM-L6-v2 (384-dim, fast)
- **CPU**: same model, slightly slower

### 5. Load Patterns (Optional)

```bash
# Download patterns from repositories
python -m prism_mcp.bootstrap.download_patterns

# Load into Qdrant (~11,800 patterns)
python -m prism_mcp.bootstrap.load_patterns_to_db
```

### 6. Start Services

```bash
# HTTP API (port 8090)
python -m prism_mcp.interfaces.http_api

# Or MCP Server (stdio)
python -m prism_mcp.interfaces.mcp_server
```

## Usage

### HTTP API

21 endpoints available at `http://localhost:8090`:

**Memory Operations**:
- `POST /api/store_memory` - Store a memory
- `POST /api/retrieve_memories` - Intelligent retrieval (requires session_id)
- `POST /api/record_feedback` - Record memory utility feedback

**Pattern Detection**:
- `POST /api/detect_patterns` - Detect patterns in code
- `POST /api/track_intervention` - Learn from corrections

**Session Management**:
- `POST /api/end_session` - End session and promote memories
- `GET /api/get_session_state` - Get current session state
- `POST /api/store_task_state` - Store task progress

**Code Indexing**:
- `POST /api/index_project` - Index entire project
- `POST /api/index_update` - Incremental git diff update
- `POST /api/query_context` - Get relevant code context

**Preference Management** (Phases 4-5):
- `POST /api/suggest_preference` - Create preference candidate
- `POST /api/approve_preference` - Approve and ground in code
- `POST /api/reject_preference` - Reject with learning
- `POST /api/list_preferences` - Query preferences

See HTTP API documentation for full endpoint list (21 total).

### MCP Tools

18 MCP tools available:

**Core**: `prism_retrieve_memories`, `prism_record_memory_feedback`, `prism_store_memory`

**Pattern**: `prism_detect_patterns`, `prism_track_intervention`

**Session**: `prism_end_session`, `prism_get_session_state`, `prism_store_task_state`

**Code**: `prism_index_project`, `prism_index_update`, `prism_query_context`

**IMPORTANT**: `prism_retrieve_memories` now requires `session_id` parameter (breaking change from v1.0).

### Example: Intelligent Retrieval

```python
import httpx

response = httpx.post("http://localhost:8090/api/retrieve_memories", json={
    "query": "authentication patterns",
    "session_id": "my-session-123",  # REQUIRED
    "role": "architect",             # Optional context
    "task_type": "skeleton",         # Optional context
    "limit": 10,
    "return_scores": True            # For debugging
}, headers={"Authorization": "Bearer your_api_key"})

data = response.json()
print(f"Retrieval ID: {data['retrieval_id']}")  # For feedback
print(f"Memories: {len(data['memories'])}")

# Later: provide feedback
httpx.post("http://localhost:8090/api/record_feedback", json={
    "retrieval_id": data['retrieval_id'],
    "memory_id": data['memories'][0]['memory_id'],
    "used": True,
    "helpful": True,
    "reason": "Helped design authentication flow"
}, headers={"Authorization": "Bearer your_api_key"})
```

## Architecture

### Storage
- **Qdrant**: Memory embeddings, pattern embeddings, code symbols
- **Neo4j**: Memory relationships, graph algorithms (PageRank, Louvain), task states
- **Redis**: Session cache only (24h TTL)

### Core Components
- **RetrievalCoordinator**: Orchestrates 6-stage intelligent retrieval
- **UtilityTracker**: Tracks memory usefulness with hierarchical feedback
- **PatternEngine**: Hybrid AST + semantic detection
- **MemoryEngine**: 4-tier memory with auto-promotion
- **IndexManager**: Code indexing and incremental updates
- **ContextProvider**: Smart code context queries

### Intelligent Retrieval Pipeline

1. **SemanticSearcher**: Qdrant similarity search with quality gate
2. **GraphExpander**: Neo4j BFS + PageRank expansion (optional)
3. **ContextFilter**: Deduplication + compatibility filtering
4. **TemporalRanker**: Age decay + recency + git SHA boost
5. **DiversitySelector**: MMR algorithm + Louvain communities
6. **Final Scoring**: Weighted combination of all signals + utility

Default weights: semantic=0.40, graph=0.30, temporal=0.20, utility=0.10

## Configuration

Key configuration sections in `config.yaml`:

```yaml
intelligent_retrieval:
  semantic:
    min_similarity_threshold: 0.70
    initial_candidate_pool: 50

  graph:
    expansion_enabled: true
    top_k_seeds: 10
    max_depth: 2

  scoring:
    weights:
      semantic: 0.40
      graph: 0.30
      temporal: 0.20
      utility: 0.10  # Must sum to 1.0

  utility:
    track_feedback: true
    feedback_ttl_days: 180
    min_feedback_samples: 3
```

## Testing

```bash
# Run all tests
pytest

# Run specific component tests
pytest tests/core/test_retrieval_coordinator.py
pytest tests/core/test_utility_tracker.py

# With coverage
pytest --cov=prism_mcp --cov-report=html
```

## Project Structure

```
prism_mcp/
├── prism_mcp/              # Core package
│   ├── core/               # Core logic (orchestrator, memory, retrieval, preferences)
│   ├── models/             # Embedding models (E5, StarCoder2, BGE)
│   ├── storage/            # Storage managers (Qdrant, Neo4j, Redis)
│   ├── interfaces/         # APIs (HTTP, MCP)
│   ├── utils/              # Utilities (config, concept extraction)
│   └── bootstrap/          # Setup scripts
├── tests/                  # Test suite
├── docs/                   # Comprehensive documentation
├── config/                 # Configuration files
└── README.md               # This file
```

## Documentation

- **CLAUDE.md**: Concise guide for AI agents
- **docs/IMPLEMENTATION_NOTES.md**: Phase 4/5 implementation and bug fixes
- **docs/ULTIMATE_ARCHITECTURE_SPEC.md**: Complete system architecture
- **docs/PREFERENCE_MEMORY_SPEC.md**: Preference learning specification
- **docs/PHASE_2_6_FINAL_SPEC.md**: Future work specification
- **docs/PHASE*_REVIEW.md**: Technical phase reviews

## Troubleshooting

### Pattern Detection Failing
- Ensure patterns loaded: `python -m prism_mcp.bootstrap.load_patterns_to_db`
- Check Qdrant: `curl http://localhost:6333/collections`

### Retrieval Returns Empty
- Check Neo4j is running: `curl http://localhost:7474`
- Verify memories stored: Check Qdrant collection `memories`
- Ensure session_id provided (now REQUIRED)

### Graph Scores Always Zero
- Fixed in v1.1 - ensure you're running latest version
- Verify `graph.expansion_enabled: true` in config

### Feedback Loop Not Working
- Fixed in v1.1 - `retrieval_id` now returned in all responses
- Verify Redis is running: `redis-cli ping`

## Contributing

This project follows strict coding standards:
- NO DEFAULTS - system crashes on missing config
- Fail loud - no silent fallbacks
- Single responsibility - one job per component
- Complete implementations - no TODO comments in production code

## License

MIT

---

**Status**: Production-ready (Phases 1-5 complete). Intelligent retrieval with 6-stage pipeline, preference memory system with code grounding, orchestration integration. 10/10 validation tests passing. All systems operational.