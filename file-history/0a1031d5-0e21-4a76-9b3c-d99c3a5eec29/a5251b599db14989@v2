# PRISM MCP - Intelligent AI Memory System

**P**attern **R**ecognition and **I**ntelligent **S**ystem **M**emory

AI memory system with 6-stage intelligent retrieval, pattern detection (155K+ patterns), and preference learning.

## What It Does

- **Remembers patterns** from 155K+ real code examples (Django, Flask, FastAPI, Go, JavaScript)
- **Learns your preferences** from corrections and interventions
- **Retrieves intelligently** using semantic search + graph analysis + temporal ranking
- **Manages memory tiers** - promotes frequently used patterns automatically
- **Integrates with Claude Code** via MCP protocol

## Quick Start

### Prerequisites

- **Python 3.10+** with pip
- **nerdctl & containerd** (container runtime)
- **8GB+ RAM** (16GB recommended)
- **10GB disk space** for models and patterns
- **GPU optional**: 8-24GB VRAM for optimal performance

### Installation

```bash
# 1. Install Python packages
pip install -r requirements.txt

# 2. Start database containers
nerdctl run -d --name prism-neo4j --network host \
  -e NEO4J_AUTH=neo4j/prism_neo4j_2024 \
  -e NEO4J_PLUGINS='["graph-data-science"]' \
  neo4j:5.13-community

nerdctl run -d --name prism-qdrant --network host \
  qdrant/qdrant:v1.7.4

nerdctl run -d --name prism-redis --network host \
  redis:7-alpine redis-server --port 6379

# 3. Download AI models (~2-5GB)
python -m prism_mcp.bootstrap.download_models

# 4. Start API server
python -m prism_mcp.interfaces.http_api --port 8090

# 5. Load patterns (in another terminal, ~3 hours for 155K patterns)
python -m prism_mcp.bootstrap.load_patterns_via_api \
  --api-url http://localhost:8090 \
  --api-key prism_development_key_2024 \
  --batch-size 50
```

### Verify Setup

```bash
# Check system health
curl http://localhost:8090/health

# Check pattern count
curl http://localhost:6333/collections/code_patterns
```

## Configuration

Edit `config/config.yaml`:

```yaml
# Database connections
database:
  neo4j_uri: "bolt://localhost:7687"
  neo4j_password: "prism_neo4j_2024"
  qdrant_url: "http://localhost:6333"
  redis_url: "redis://localhost:6379"

# Model tier (1=Full, 2=Dual, 3=Single, 4=CPU, 5=Keyword)
models:
  tier_strategy: "manual"
  manual_tier: 1  # Full tier: E5-Mistral + StarCoder2 + BGE-Reranker
```

## Usage

### As MCP Server

Add to Claude Code's `~/.config/claude/mcp_config.json`:

```json
{
  "mcpServers": {
    "prism": {
      "command": "python",
      "args": ["-m", "prism_mcp.interfaces.mcp_server"],
      "cwd": "/path/to/prism_mcp"
    }
  }
}
```

### Via HTTP API

```python
import httpx

# Store a memory
response = httpx.post(
    "http://localhost:8090/api/memories",
    json={
        "content": "Use type hints for all function parameters",
        "memory_type": "guidance",
        "session_id": "session_123",
        "tags": ["python", "type-safety"]
    },
    headers={"Authorization": "Bearer prism_development_key_2024"}
)

# Retrieve memories
response = httpx.post(
    "http://localhost:8090/api/memories/retrieve",
    json={
        "query": "How should I handle function parameters?",
        "session_id": "session_123",
        "limit": 5
    },
    headers={"Authorization": "Bearer prism_development_key_2024"}
)
```

## System Architecture

### Three-Model System (FULL Tier)
- **E5-Mistral-7B** (4096 dims) - Semantic understanding for notes/decisions/guidance
- **StarCoder2-7B** (4608 dims) - Code pattern embeddings
- **BGE-Reranker-v2-m3** - Precision boost via cross-encoder

### 6-Stage Retrieval Pipeline
1. **Semantic Search** - Vector similarity in Qdrant
2. **Graph Expansion** - PageRank + BFS traversal in Neo4j
3. **Context Filtering** - Role/task/project compatibility
4. **Temporal Ranking** - Recency and git SHA matching
5. **Diversity Selection** - MMR + Louvain clustering
6. **Utility Scoring** - Feedback-driven effectiveness

### 4-Tier Memory System
- **ANCHORS** - High-frustration patterns (user explicitly corrected)
- **LONGTERM** - Frequently accessed (access_count ≥ 5)
- **EPISODIC** - Recent session discoveries
- **WORKING** - Current session only (TTL cleanup)

## Troubleshooting

### GPU Out of Memory

If you see OOM errors:

```yaml
# Switch to Single tier (E5 only)
models:
  manual_tier: 3
```

Or use CPU mode:

```yaml
models:
  manual_tier: 4
```

### Pattern Loading Slow

Pattern loading takes ~3 hours for 155K patterns. Monitor progress:

```bash
tail -f /tmp/pattern_load_api.log
```

### Database Connection Issues

Check containers are running:

```bash
nerdctl ps | grep prism
```

Restart if needed:

```bash
nerdctl restart prism-neo4j prism-qdrant prism-redis
```

## Key Files

### For Users
- `README.md` - This file
- `config/config.yaml` - Main configuration
- `SETUP_GPU.md` - GPU-specific setup guide

### For AI Agents
- `CLAUDE.md` - Essential technical context
- `docs/IMPLEMENTATION_NOTES.md` - Implementation details and fixes
- `docs/ULTIMATE_ARCHITECTURE_SPEC.md` - Complete architecture (88K words)

### For Developers
- `docs/INTELLIGENT_RETRIEVAL_SPEC.md` - Retrieval pipeline spec
- `docs/PREFERENCE_MEMORY_SPEC.md` - Preference learning spec
- `docs/archive/` - Historical phase reviews

## Recent Fixes (2025-09-29)

**Critical Model Loading Bug Fixed**

Root cause: All three models used `device_map="auto"` but tried to verify dimensions with CPU tensors → device mismatch crash.

Fix: Skip dimension verification when using `device_map` (models are pre-validated).

Files fixed:
- `prism_mcp/models/quantization.py:223-227` (StarCoder2)
- `prism_mcp/models/quantization.py:275-279` (BGE-Reranker)

Impact: Unblocked entire pattern recognition system. System now 90% functional.

## Support

- **Issues**: File issues at project repository
- **Documentation**: See `docs/` directory
- **Health Check**: `curl http://localhost:8090/api/health/detailed`

---

**NO DEFAULTS Philosophy**: This system fails loudly rather than degrading silently. All configuration must be explicit.