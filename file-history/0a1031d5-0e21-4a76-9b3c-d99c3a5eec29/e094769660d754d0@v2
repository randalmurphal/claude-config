# API Comparison Tests

Testing Voyage AI premium embeddings vs local models.

## Quick Start

### 1. Install Dependencies

```bash
pip install voyageai
```

### 2. Get API Keys

#### Voyage AI (FREE 200M tokens)
1. Go to: https://www.voyageai.com/
2. Click "Sign Up" (top right)
3. Verify email
4. Dashboard → API Keys → Create new key
5. Copy the key (starts with `pa-`)

#### Jina AI (FREE 10M tokens) - Optional for reranking tests
1. Go to: https://jina.ai/
2. Sign up
3. Dashboard → API Keys → Generate
4. Copy the key

### 3. Set Environment Variables

```bash
export VOYAGE_API_KEY="pa-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
export JINA_API_KEY="jina-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"  # optional
```

### 4. Run Tests

```bash
cd /home/randy/repos/claude_mcp/prism_mcp/tests/api_comparison
python test_voyage_vs_local.py
```

## What It Tests

**Code Embeddings:**
- Local: StarCoder2-7B (4608d, 8-bit quantized, ~6.5GB VRAM)
- API: voyage-code-3 (optimized for code retrieval)

**Semantic Embeddings:**
- Local: E5-Mistral-7B (4096d, 8-bit quantized, ~10GB VRAM)
- API: voyage-3-large (1024d default, 32K context)

**Metrics:**
- Retrieval precision (top-5 accuracy)
- Latency (local GPU vs API network call)
- Cost estimation
- Pattern overlap analysis

## Expected Results

**Precision:** API should show +10-20% improvement on code retrieval
**Latency:** Local ~10-50ms, API ~100-300ms
**Cost:** First 200M tokens FREE (enough for 2+ years of heavy use)

## Sample Output

```
================================================================================
VOYAGE API vs LOCAL MODELS COMPARISON
================================================================================

1. Initializing embedders...
Loading local models (E5-Mistral + StarCoder2)...
✓ Local models loaded
✓ Both embedders ready

2. Loading sample patterns from Qdrant...
✓ Loaded 100 patterns

3. Running comparison tests...

CODE QUERIES:

  Testing: JWT authentication with refresh tokens
  Local embedding... 42ms
  API embedding... 156ms (1,245 tokens)

  Testing: async database connection pooling
  Local embedding... 38ms
  API embedding... 148ms (1,189 tokens)

...

================================================================================
SUMMARY
================================================================================

CODE QUERIES:
  Average overlap: 3.2/5 patterns
  Precision improvement: +15.3%
  Latency: Local 45ms vs API 165ms
  Total tokens: 6,234
  Cost: FREE (within 200M token limit)

SEMANTIC QUERIES:
  Average overlap: 3.8/5 patterns
  Precision improvement: +12.1%
  Latency: Local 52ms vs API 172ms
  Total tokens: 5,891
  Cost: FREE (within 200M token limit)

================================================================================
RECOMMENDATION
================================================================================
✅ API embeddings show significant improvement (+10% precision)
   Recommend: Implement Tier 0 (PREMIUM_API)
```

## Next Steps

If results look good:

1. **Implement Tier 0** - Add API embedders to production code
2. **Migrate patterns** - Re-embed 155K patterns with Voyage (takes 2-3 hours)
3. **Configure** - Update config.yaml with API keys
4. **Enjoy** - Better quality, zero GPU requirements, basically free for 2 years

## Troubleshooting

**"VOYAGE_API_KEY not set"**
→ Run: `export VOYAGE_API_KEY="your-key-here"`

**"No patterns found in Qdrant"**
→ Script will use synthetic patterns for testing (still valid comparison)

**"voyageai package not installed"**
→ Run: `pip install voyageai`

**"Local models not loading"**
→ Check that prism_mcp is running and models are downloaded