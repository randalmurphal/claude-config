"""
Configuration management for PRISM MCP.

NO DEFAULTS PHILOSOPHY:
- Every configuration value MUST be explicitly set
- Missing configuration causes immediate failure
- No silent fallbacks or arbitrary defaults
- Clear error messages indicating what's missing
"""

import os
import yaml
from pathlib import Path
from typing import Any, Dict, List, Optional
from pydantic import BaseModel, Field, ValidationError

from prism_mcp.utils.error_messages import ConfigError, SetupError


class DatabaseConfig(BaseModel):
    """Database connection configuration."""

    neo4j_uri: str = Field(..., description="Neo4j connection URI")
    neo4j_user: str = Field(..., description="Neo4j username")
    neo4j_password: str = Field(..., description="Neo4j password")
    qdrant_url: str = Field(..., description="Qdrant connection URL")
    redis_url: str = Field(..., description="Redis connection URL")


class DataConfig(BaseModel):
    """Data storage configuration."""

    base_path: str = Field(..., description="Base path for data storage (supports ~)")
    patterns_dir: str = Field(..., description="Patterns subdirectory")
    models_dir: str = Field(..., description="Models subdirectory")
    repos_cache_dir: str = Field(..., description="Repository cache subdirectory")
    processed_patterns_dir: str = Field(..., description="Processed patterns subdirectory")


class ModelConfig(BaseModel):
    """ML model configuration."""

    # These are runtime-detected, not configured
    model_name: Optional[str] = Field(None, description="Model name - auto-detected at runtime")
    embedding_dim: Optional[int] = Field(None, description="Embedding dimensions - auto-detected")
    device: Optional[str] = Field(None, description="Compute device - auto-detected")

    # These are configured
    use_quantization: bool = Field(..., description="Use INT8 quantization")
    max_sequence_length: int = Field(..., description="Maximum input sequence length")
    dtype: str = Field(..., description="Model dtype: 'float32', 'float16', or 'bfloat16'")


class TierRequirementConfig(BaseModel):
    """Single tier requirement configuration."""
    min_vram_gb: float = Field(..., description="Minimum VRAM required in GB")
    models: List[str] = Field(..., description="List of models for this tier")
    device: Optional[str] = Field(None, description="Device override (e.g., 'cpu')")
    bm25_only: Optional[bool] = Field(None, description="Use only BM25 (keyword tier)")


class TierRequirementsConfig(BaseModel):
    """All tier requirements configuration."""
    full: TierRequirementConfig
    dual: TierRequirementConfig
    single: TierRequirementConfig
    cpu: TierRequirementConfig
    keyword: TierRequirementConfig


class ModelsConfig(BaseModel):
    """Models tier configuration."""

    tier_strategy: str = Field(..., description="Tier strategy: 'auto' or 'manual'")
    manual_tier: Optional[int] = Field(None, description="Manual tier override (1-5)")
    tier_requirements: TierRequirementsConfig = Field(..., description="Tier requirements for auto-detection")
    base_path: str = Field(..., description="Base path for models")
    fallback_to_hf_cache: bool = Field(..., description="Fallback to HuggingFace cache if model not found")


class QueryAugmentationConfig(BaseModel):
    """Query augmentation configuration (Phase 3.1 - Learned Negations)."""

    enable_learned_negations: bool = Field(..., description="Load learned negations from Neo4j")
    reload_interval_queries: int = Field(..., description="Reload learned negations every N queries (0 = never)")
    min_confidence: float = Field(..., description="Minimum confidence to use learned negation (0.0-1.0)")
    negation_decay_half_life_days: int = Field(..., description="Phase 3.4: Half-life for confidence decay (0 = no decay)")


class AdaptiveThresholdsConfig(BaseModel):
    """Adaptive thresholds configuration (Phase 3.2 - Learned Thresholds)."""

    enable_adaptive_thresholds: bool = Field(..., description="Use learned thresholds from Neo4j")
    lookback_days: int = Field(..., description="Days of feedback to analyze")
    min_samples: int = Field(..., description="Minimum feedback samples before learning threshold")
    f_beta: float = Field(..., description="F-score beta parameter (1.0 = F1)")
    default_threshold: float = Field(..., description="Default threshold when no learned threshold available")


class ServerConfig(BaseModel):
    """Server configuration."""

    http_host: str = Field(..., description="HTTP server host")
    http_port: int = Field(..., description="HTTP server port")
    mcp_enabled: bool = Field(..., description="Enable MCP server")
    api_key: str = Field(..., description="API key for HTTP authentication")


class ThresholdConfig(BaseModel):
    """Default thresholds that get improved by learning."""

    # Pattern detection thresholds
    confidence_threshold: float = Field(..., description="Minimum confidence to report pattern")
    semantic_similarity_threshold: float = Field(..., description="Minimum similarity for semantic match")

    # Weight balance for hybrid scoring
    ast_confidence_weight: float = Field(..., description="Weight for AST structural matches")
    semantic_only_confidence_weight: float = Field(..., description="Weight for pure semantic matches")
    combined_confidence_weight: float = Field(..., description="Weight when both AST and semantic match")



class DriftConfig(BaseModel):
    """Drift detection configuration."""

    drift_threshold: float = Field(..., description="Threshold for drift detection")
    min_confidence_for_intervention: float = Field(..., description="Minimum confidence to trigger intervention")


class LearningConfig(BaseModel):
    """Learning engine configuration - NO DEFAULTS."""

    observation_window_size: int = Field(..., description="Size of sliding window for observations")
    min_observations_required: int = Field(..., description="Minimum observations before learning")
    percentile_for_threshold: float = Field(..., description="Percentile for threshold calculation (0-100)")
    z_score_multiplier: float = Field(..., description="Z-score multiplier for adaptive thresholds")
    significant_change_threshold: float = Field(..., description="Similarity threshold for significant changes")
    universal_pattern_threshold: int = Field(..., description="Number of projects required for universal pattern status")


class CacheConfig(BaseModel):
    """Redis cache configuration - NO DEFAULTS."""

    default_ttl_seconds: int = Field(..., description="Default TTL for cached items in seconds")
    max_key_length: int = Field(..., description="Maximum length for cache keys")


class ImportanceWeights(BaseModel):
    """Memory importance weight configuration."""
    graph: float = Field(..., description="PageRank/centrality weight")
    access: float = Field(..., description="Access frequency weight")
    frustration: float = Field(..., description="Frustration signal weight")


class MemoryConfig(BaseModel):
    """Memory tiering configuration - NO DEFAULTS."""

    to_anchors_frustration: float = Field(..., description="Frustration level for ANCHORS tier")
    to_longterm_accesses: int = Field(..., description="Access count for LONGTERM promotion")
    to_episodic_age_hours: float = Field(..., description="Age in hours for EPISODIC demotion")
    working_ttl_hours: float = Field(..., description="TTL for WORKING memory in hours")
    importance_weights: ImportanceWeights = Field(..., description="Importance calculation weights")


class MAPIEConfig(BaseModel):
    """MAPIE confidence prediction configuration - NO DEFAULTS."""

    alpha: float = Field(..., description="Alpha for prediction intervals (1-alpha = coverage)")
    method: str = Field(..., description="MAPIE method: plus, base, or minmax")
    n_estimators: int = Field(..., description="Random forest estimators")
    max_depth: int = Field(..., description="Random forest max depth")
    cv_folds: int = Field(..., description="Cross-validation folds")


class SemanticSearchConfig(BaseModel):
    """Stage 1: Semantic search configuration - NO DEFAULTS."""
    min_similarity_threshold: float = Field(..., description="Minimum similarity score (0.0-1.0)")
    initial_candidate_pool: int = Field(..., description="Initial candidates from semantic search")
    distance_metric: str = Field(..., description="Distance metric (cosine, dot, euclidean)")


class GraphExpansionConfig(BaseModel):
    """Stage 2: Graph expansion configuration - NO DEFAULTS."""
    expansion_enabled: bool = Field(..., description="Enable graph expansion")
    max_depth: int = Field(..., description="BFS traversal depth")
    top_k_seeds: int = Field(..., description="Top K semantic results to expand from")
    relationship_types: list[str] = Field(..., description="Which relationships to traverse")
    pagerank_weight: float = Field(..., description="PageRank influence on expansion score")


class ContextFilterConfig(BaseModel):
    """Stage 3: Context filtering configuration - NO DEFAULTS."""
    enforce_role_compatibility: bool = Field(..., description="Filter by applicable_roles (if role provided)")
    enforce_task_compatibility: bool = Field(..., description="Filter by applicable_task_types")
    enforce_phase_compatibility: bool = Field(..., description="Filter by applicable_phases")
    deduplicate_by_session: bool = Field(..., description="Session-level deduplication")
    deduplicate_by_task: bool = Field(..., description="Task-level deduplication (if task_id provided)")


class TemporalRankingConfig(BaseModel):
    """Stage 4: Temporal ranking configuration - NO DEFAULTS."""
    recency_weight: float = Field(..., description="Weight for temporal score")
    decay_halflife_days: int = Field(..., description="Days for memory to lose half its value")
    boost_current_git_sha: bool = Field(..., description="Boost memories from current commit")
    sha_boost_factor: float = Field(..., description="Multiplier for current SHA memories")
    anchor_tier_exempt: bool = Field(..., description="ANCHORS tier doesn't decay")


class DiversitySelectionConfig(BaseModel):
    """Stage 5: Diversity selection configuration - NO DEFAULTS."""
    enabled: bool = Field(..., description="Enable diversity selection")
    mmr_lambda: float = Field(..., description="MMR balance (1.0=relevance, 0.0=diversity)")
    min_cluster_representation: int = Field(..., description="Max memories per cluster")
    use_louvain_communities: bool = Field(..., description="Use Neo4j Louvain for clustering")


class ScoringWeights(BaseModel):
    """Final scoring weights - NO DEFAULTS."""
    semantic: float = Field(..., description="Semantic similarity weight")
    graph: float = Field(..., description="Graph importance weight")
    temporal: float = Field(..., description="Temporal relevance weight")
    utility: float = Field(..., description="Historical utility weight")


class FinalScoringConfig(BaseModel):
    """Stage 6: Final scoring configuration - NO DEFAULTS."""
    weights: ScoringWeights = Field(..., description="Score combination weights")
    final_limit: int = Field(..., description="Final number of results")


class UtilityTrackingConfig(BaseModel):
    """Utility tracking configuration - NO DEFAULTS."""
    track_feedback: bool = Field(..., description="Enable utility tracking")
    feedback_ttl_days: int = Field(..., description="Days to keep feedback data")
    min_feedback_samples: int = Field(..., description="Min samples before using utility score")


class BackgroundJobsConfig(BaseModel):
    """Background job intervals - NO DEFAULTS."""
    pagerank_update_interval_seconds: int = Field(..., description="PageRank update interval")
    louvain_update_interval_seconds: int = Field(..., description="Louvain update interval")
    temporal_update_interval_seconds: int = Field(..., description="Temporal scores update interval")
    cleanup_interval_seconds: int = Field(..., description="Cleanup stale data interval")


class IntelligentRetrievalConfig(BaseModel):
    """Complete intelligent retrieval configuration - NO DEFAULTS."""
    semantic: SemanticSearchConfig = Field(..., description="Stage 1: Semantic search")
    graph: GraphExpansionConfig = Field(..., description="Stage 2: Graph expansion")
    context: ContextFilterConfig = Field(..., description="Stage 3: Context filtering")
    temporal: TemporalRankingConfig = Field(..., description="Stage 4: Temporal ranking")
    diversity: DiversitySelectionConfig = Field(..., description="Stage 5: Diversity selection")
    scoring: FinalScoringConfig = Field(..., description="Stage 6: Final scoring")
    utility: UtilityTrackingConfig = Field(..., description="Utility tracking")
    background: BackgroundJobsConfig = Field(..., description="Background jobs")


class SimilarityThresholds(BaseModel):
    """Mode-specific similarity thresholds for cache hits."""
    lightning: float = Field(..., description="Lightning mode threshold")
    fast: float = Field(..., description="Fast mode threshold")
    balanced: float = Field(..., description="Balanced mode threshold")
    comprehensive: float = Field(..., description="Comprehensive mode threshold")


class RetrievalCacheConfig(BaseModel):
    """Retrieval cache configuration - NO DEFAULTS."""
    query_ttl_seconds: int = Field(..., description="Query cache TTL in seconds")
    embedding_ttl_seconds: int = Field(..., description="Embedding cache TTL in seconds")
    similarity_thresholds: SimilarityThresholds = Field(..., description="Mode-specific similarity thresholds")
    distributed_lock_ttl_seconds: int = Field(..., description="Distributed lock TTL in seconds")
    enabled: bool = Field(..., description="Enable caching")


class RetrievalModeConfig(BaseModel):
    """Configuration for a single retrieval mode."""
    timeout_ms: int = Field(..., description="Timeout in milliseconds")
    fallback_to_anchors: bool = Field(False, description="Fallback to ANCHORS tier")
    skip_stages: list[str] = Field(default_factory=list, description="Stages to skip")
    graph_depth: int = Field(1, description="Graph expansion depth")
    description: str = Field(..., description="Mode description")


class RetrievalConfig(BaseModel):
    """Retrieval modes configuration - NO DEFAULTS."""
    default_mode: str = Field(..., description="Default retrieval mode")
    modes: Dict[str, RetrievalModeConfig] = Field(..., description="Mode definitions")
    phase_mapping: Dict[str, str] = Field(..., description="Phase to mode mapping")
    cache: RetrievalCacheConfig = Field(..., description="Cache configuration")


class SignalWeights(BaseModel):
    """Effectiveness signal weights."""
    gate_outcomes: float = Field(..., description="Weight for gate outcomes")
    session_completions: float = Field(..., description="Weight for session completions")
    file_changes: float = Field(..., description="Weight for file changes")
    interventions: float = Field(..., description="Weight for interventions")


class EffectivenessConfig(BaseModel):
    """Effectiveness tracking configuration."""
    min_samples_required: int = Field(..., description="Minimum samples for effectiveness calculation")
    signal_weights: SignalWeights = Field(..., description="Signal weights")
    temporal_decay_factor: float = Field(..., description="Temporal decay factor per day")


class DriftDetectionConfig(BaseModel):
    """Drift detection configuration for analytics."""
    enabled: bool = Field(..., description="Enable drift detection")
    embedding_similarity_threshold: float = Field(..., description="Similarity threshold")
    check_interval_days: int = Field(..., description="Check interval in days")


class RecommendationsConfig(BaseModel):
    """Recommendations configuration."""
    unused_threshold_days: int = Field(..., description="Days before considering unused")
    ineffective_threshold: float = Field(..., description="Effectiveness threshold")
    min_usage_for_recommendation: int = Field(..., description="Minimum usage count")


class StorageConfig(BaseModel):
    """Analytics storage configuration."""
    backend: str = Field(..., description="Storage backend (neo4j)")
    retention_days: int = Field(..., description="Data retention in days")


class AnalyticsConfig(BaseModel):
    """Complete analytics configuration."""
    enabled: bool = Field(..., description="Enable analytics")
    effectiveness: EffectivenessConfig = Field(..., description="Effectiveness tracking")
    drift_detection: DriftDetectionConfig = Field(..., description="Drift detection")
    recommendations: RecommendationsConfig = Field(..., description="Recommendations")
    storage: StorageConfig = Field(..., description="Storage configuration")


# Phase 4: Critical Integrations Configuration
class ClaudeMdConfig(BaseModel):
    """CLAUDE.md bidirectional sync configuration."""
    enabled: bool = Field(..., description="Enable CLAUDE.md sync")
    auto_sync: bool = Field(..., description="Auto-sync without manual approval")
    watched_sections: list[str] = Field(..., description="CLAUDE.md sections to watch")
    export_threshold: dict = Field(..., description="Export threshold settings")
    import_tier: str = Field(..., description="Memory tier for imported preferences")


class PreToolUseConfig(BaseModel):
    """PreToolUse hook configuration."""
    retrieval_mode: str = Field(..., description="Retrieval mode for pre-tool hook")
    timeout_ms: int = Field(..., description="Timeout in milliseconds")
    block_on_critical: bool = Field(..., description="Block on critical patterns")
    inject_context: bool = Field(..., description="Inject retrieved context")


class PostToolUseConfig(BaseModel):
    """PostToolUse hook configuration."""
    async_: bool = Field(..., alias="async", description="Process asynchronously")
    pattern_detection: bool = Field(..., description="Enable pattern detection")
    auto_preference_threshold: float = Field(..., description="Auto-preference threshold")
    log_file: str = Field(..., description="Path to detection log file")


class HooksConfig(BaseModel):
    """Hook integration configuration."""
    enabled: bool = Field(..., description="Enable hook integration")
    pre_tool_use: PreToolUseConfig = Field(..., description="PreToolUse hook config")
    post_tool_use: PostToolUseConfig = Field(..., description="PostToolUse hook config")


class SubAgentsConfig(BaseModel):
    """Sub-agent discovery configuration."""
    enabled: bool = Field(..., description="Enable sub-agent discovery")
    discovery_paths: list[str] = Field(..., description="Paths to search for agents")
    reload_interval_seconds: int = Field(..., description="Reload interval in seconds")


class OutputStylesConfig(BaseModel):
    """Output styles configuration."""
    enabled: bool = Field(..., description="Enable output styles")
    phase_mapping: dict = Field(..., description="Phase to style mapping")
    custom_styles_path: str = Field(..., description="Path to custom styles")


class IntegrationsConfig(BaseModel):
    """Critical integrations configuration."""
    claudemd: ClaudeMdConfig = Field(..., description="CLAUDE.md integration")
    hooks: HooksConfig = Field(..., description="Hook integration")
    subagents: SubAgentsConfig = Field(..., description="Sub-agent discovery")
    output_styles: OutputStylesConfig = Field(..., description="Output styles")


class WatcherConfig(BaseModel):
    """File watcher configuration for symbol deletion tracking."""
    enabled: bool = Field(..., description="Enable file watcher")
    debounce_ms: int = Field(..., description="Debounce file events to avoid spam")
    watched_extensions: list[str] = Field(..., description="File extensions to watch")
    ignore_patterns: list[str] = Field(..., description="Patterns to ignore")


class RealtimeConfig(BaseModel):
    """Real-time deletion detection configuration."""
    batch_size: int = Field(..., description="Process deletions in batches")
    max_batch_wait_seconds: int = Field(..., description="Maximum wait before processing partial batch")


class SymbolDeletionConfig(BaseModel):
    """Symbol deletion tracking configuration."""
    enable_deletion_tracking: bool = Field(..., description="Enable/disable symbol deletion tracking")
    deletion_retention_days: int = Field(..., description="How long to retain deletion records (days)")
    reconciliation_window_hours: int = Field(..., description="Window for reconciliation to detect renames (hours)")
    min_confidence_threshold: float = Field(..., description="Minimum confidence threshold to mark symbols as deleted")
    watcher: WatcherConfig = Field(..., description="File watcher configuration")
    realtime: RealtimeConfig = Field(..., description="Real-time deletion detection")


class MetricsCollectionConfig(BaseModel):
    """Metrics collection configuration."""
    api_latency: bool = Field(..., description="API endpoint metrics")
    api_request_count: bool = Field(..., description="API request count metrics")
    database_latency: bool = Field(..., description="Database operation metrics")
    database_query_count: bool = Field(..., description="Database query count")
    cache_hit_rate: bool = Field(..., description="Cache operation metrics")
    cache_latency: bool = Field(..., description="Cache latency")
    memory_tier_access: bool = Field(..., description="Memory tier access patterns")
    pattern_detection_latency: bool = Field(..., description="Pattern detection performance")
    embedding_latency: bool = Field(..., description="Embedding generation metrics")


class MetricsThresholdsConfig(BaseModel):
    """Alerting thresholds for metrics."""
    api_latency_p95_ms: int = Field(..., description="95th percentile API latency")
    database_latency_p95_ms: int = Field(..., description="95th percentile DB latency")
    cache_hit_rate_percent: float = Field(..., description="Minimum cache hit rate")
    memory_usage_mb: int = Field(..., description="Maximum memory usage")


class MetricsConfig(BaseModel):
    """Performance metrics configuration."""
    enabled: bool = Field(..., description="Enable/disable metrics collection")
    retention_seconds: int = Field(..., description="Data retention for time-series metrics")
    max_points_per_metric: int = Field(..., description="Maximum data points per metric")
    collection_interval_seconds: int = Field(..., description="Background collection interval")
    collection: MetricsCollectionConfig = Field(..., description="Metric collection configuration")
    thresholds: MetricsThresholdsConfig = Field(..., description="Alerting thresholds")


class PatternsConfig(BaseModel):
    """Pattern loading configuration."""
    memory_warning_threshold_gb: float = Field(..., description="Warning threshold for memory usage (GB)")
    max_patterns_to_load: int = Field(..., description="Maximum patterns to load (0 = unlimited)")


class PRISMConfig(BaseModel):
    """Complete PRISM configuration."""

    database: DatabaseConfig
    data: DataConfig
    model: ModelConfig
    query_augmentation: QueryAugmentationConfig  # Phase 3.1: Learned negations
    adaptive_thresholds: AdaptiveThresholdsConfig  # Phase 3.2: Adaptive thresholds
    server: ServerConfig
    thresholds: ThresholdConfig  # Default thresholds improved by learning
    drift: DriftConfig  # Drift detection config
    learning: LearningConfig
    cache: CacheConfig
    memory: MemoryConfig
    mapie: MAPIEConfig  # REQUIRED for confidence prediction
    intelligent_retrieval: IntelligentRetrievalConfig  # REQUIRED for intelligent memory retrieval
    retrieval: RetrievalConfig  # REQUIRED for retrieval modes and cache
    analytics: AnalyticsConfig  # REQUIRED for preference analytics
    models: ModelsConfig  # REQUIRED for tier detection
    integrations: IntegrationsConfig  # Phase 4: Critical integrations
    symbol_deletion: SymbolDeletionConfig  # Symbol deletion tracking
    metrics: MetricsConfig  # Performance metrics
    patterns: PatternsConfig  # Pattern loading configuration

    # Feature flags
    enable_learning: bool = Field(..., description="Enable continuous learning")
    enable_drift_detection: bool = Field(..., description="Enable drift detection")
    enable_pattern_learning: bool = Field(..., description="Enable pattern learning")


class ConfigLoader:
    """
    Configuration loader with NO DEFAULTS philosophy.

    Every value must be explicitly configured.
    Missing values cause immediate failure.
    """

    def __init__(self, config_path: Optional[str] = None):
        """
        Initialize configuration loader.

        Args:
            config_path: Path to configuration file. If not provided,
                        looks for PRISM_CONFIG env var, then config/config.yaml
        """
        self.config_path = self._find_config_file(config_path)
        self.config: Optional[PRISMConfig] = None

    def _find_config_file(self, config_path: Optional[str]) -> Path:
        """Find configuration file - NO DEFAULT CONFIG."""
        if config_path:
            path = Path(config_path)
            if not path.exists():
                raise FileNotFoundError(
                    f"Configuration file not found: {config_path}\n"
                    f"Create a configuration file or set PRISM_CONFIG environment variable."
                )
            return path

        # Check environment variable
        env_config = os.environ.get('PRISM_CONFIG')
        if env_config:
            path = Path(env_config)
            if not path.exists():
                raise FileNotFoundError(
                    f"Configuration file specified in PRISM_CONFIG not found: {env_config}"
                )
            return path

        # Check standard location
        standard_path = Path(__file__).parent.parent.parent / 'config' / 'config.yaml'
        if not standard_path.exists():
            raise FileNotFoundError(
                "No configuration file found.\n"
                "Please provide configuration via:\n"
                "1. --config flag\n"
                "2. PRISM_CONFIG environment variable\n"
                "3. Create config/config.yaml\n\n"
                "Example configuration template at: config/config.template.yaml"
            )

        return standard_path

    def load(self) -> PRISMConfig:
        """
        Load and validate configuration.

        Returns:
            Validated configuration object

        Raises:
            FileNotFoundError: If config file not found
            ValidationError: If config validation fails
            ValueError: If required values are missing
        """
        if self.config is not None:
            return self.config

        # Load YAML
        with open(self.config_path, 'r') as f:
            raw_config = yaml.safe_load(f)

        if not raw_config:
            raise SetupError(
                "configuration_loading",
                f"Configuration file is empty: {self.config_path}",
                "Copy from template: cp config/config.template.yaml config/config.yaml"
            )

        # Override with environment variables if present
        raw_config = self._apply_env_overrides(raw_config)

        # Validate with Pydantic - will fail if ANY required field is missing
        try:
            self.config = PRISMConfig(**raw_config)
        except ValidationError as e:
            # Create enhanced error messages for missing fields
            missing_fields = []
            for error in e.errors():
                field_path = '.'.join(str(loc) for loc in error['loc'])
                if error['type'] == 'missing':
                    missing_fields.append(field_path)

            if missing_fields:
                # Use the first missing field for specific guidance
                first_field = missing_fields[0]

                # Try to provide line number if possible
                line_number = None
                try:
                    with open(self.config_path, 'r') as f:
                        for i, line in enumerate(f, 1):
                            if first_field.split('.')[-1] in line:
                                line_number = i
                                break
                except:
                    pass

                raise ConfigError(
                    key=first_field,
                    config_file=str(self.config_path),
                    line=line_number
                )
            else:
                # For other validation errors, provide general guidance
                raise SetupError(
                    "configuration_validation",
                    str(e),
                    "Check config.yaml format and compare with config.template.yaml"
                )

        return self.config

    def _apply_env_overrides(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """
        Apply environment variable overrides.

        Environment variables follow pattern: PRISM_SECTION_KEY
        e.g., PRISM_DATABASE_NEO4J_URI, PRISM_MODEL_EMBEDDING_DIM
        """
        # Database overrides
        if 'database' not in config:
            config['database'] = {}
        config['database']['neo4j_uri'] = os.environ.get(
            'PRISM_DATABASE_NEO4J_URI',
            config['database'].get('neo4j_uri')
        )
        config['database']['neo4j_user'] = os.environ.get(
            'PRISM_DATABASE_NEO4J_USER',
            config['database'].get('neo4j_user')
        )
        config['database']['neo4j_password'] = os.environ.get(
            'PRISM_DATABASE_NEO4J_PASSWORD',
            config['database'].get('neo4j_password')
        )
        config['database']['qdrant_url'] = os.environ.get(
            'PRISM_DATABASE_QDRANT_URL',
            config['database'].get('qdrant_url')
        )
        config['database']['redis_url'] = os.environ.get(
            'PRISM_DATABASE_REDIS_URL',
            config['database'].get('redis_url')
        )

        # Model overrides
        if 'model' not in config:
            config['model'] = {}
        config['model']['model_name'] = os.environ.get(
            'PRISM_MODEL_NAME',
            config['model'].get('model_name')
        )

        return config


# Global config instance (lazy loaded)
_config_instance: Optional[PRISMConfig] = None
_config_loader: Optional[ConfigLoader] = None


def load_config(config_path: Optional[str] = None, force_reload: bool = False) -> PRISMConfig:
    """
    Load configuration (singleton pattern).

    Args:
        config_path: Optional path to config file
        force_reload: Force reload even if already loaded

    Returns:
        Configuration object

    Raises:
        ValueError: If configuration is invalid or missing required values
    """
    global _config_instance, _config_loader

    if _config_instance is not None and not force_reload:
        return _config_instance

    _config_loader = ConfigLoader(config_path)
    _config_instance = _config_loader.load()

    return _config_instance


def get_config() -> PRISMConfig:
    """
    Get current configuration.

    Returns:
        Current configuration object

    Raises:
        SetupError: If configuration not loaded yet
    """
    if _config_instance is None:
        raise SetupError(
            "configuration_not_loaded",
            "Configuration not loaded",
            "Call load_config() first or run setup script: ./setup.sh"
        )
    return _config_instance