#!/usr/bin/env python3
"""
Comprehensive PRISM System Test Suite
Tests all major functionality and finds system limits
"""
import requests
import json
import time
from typing import Dict, List, Any

API_URL = "http://localhost:8090"
API_KEY = "prism_development_key_2024"
headers = {"Authorization": f"Bearer {API_KEY}", "Content-Type": "application/json"}

class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    END = '\033[0m'

def log_test(name: str):
    print(f"\n{'='*60}")
    print(f"{Colors.BLUE}{name}{Colors.END}")
    print(f"{'='*60}")

def log_success(msg: str):
    print(f"{Colors.GREEN}✓{Colors.END} {msg}")

def log_error(msg: str):
    print(f"{Colors.RED}✗{Colors.END} {msg}")

def log_info(msg: str):
    print(f"{Colors.YELLOW}ℹ{Colors.END} {msg}")

# =================================================================
# TEST 1: Batch Memory Storage (Stress Test)
# =================================================================
def test_batch_storage():
    log_test("TEST 1: Batch Memory Storage (100 memories)")

    start_time = time.time()
    stored_ids = []

    for i in range(100):
        memory_data = {
            "content": f"Test memory {i}: This is a sample code pattern for testing batch storage operations. "
                      f"It contains enough text to simulate real memories with meaningful content. "
                      f"Pattern ID: {i}, Category: {'code' if i % 2 == 0 else 'architecture'}",
            "memory_type": "code_pattern" if i % 2 == 0 else "research_note",
            "context": {
                "session_id": "comprehensive_test",
                "role": "assistant",
                "task": f"batch_test_{i % 10}",
                "project_id": "stress_test",
            },
            "tags": [f"batch_{i // 10}", "stress_test", "tier0"]
        }

        try:
            response = requests.post(f"{API_URL}/api/store_memory", json=memory_data, headers=headers)
            response.raise_for_status()
            result = response.json()
            stored_ids.append(result['memory_id'])
        except Exception as e:
            log_error(f"Failed to store memory {i}: {e}")
            return False

    elapsed = time.time() - start_time
    log_success(f"Stored 100 memories in {elapsed:.2f}s ({elapsed/100*1000:.1f}ms per memory)")
    log_info(f"First ID: {stored_ids[0]}, Last ID: {stored_ids[-1]}")
    return True, stored_ids

# =================================================================
# TEST 2: Retrieval Modes (All 4 modes)
# =================================================================
def test_retrieval_modes():
    log_test("TEST 2: Retrieval Modes (lightning/fast/balanced/comprehensive)")

    modes = ["lightning", "fast", "balanced", "comprehensive"]
    query = "code pattern for testing batch operations"

    for mode in modes:
        start_time = time.time()

        try:
            response = requests.post(
                f"{API_URL}/api/retrieve_memories",
                json={
                    "query": query,
                    "top_k": 5,
                    "session_id": "comprehensive_test",
                    "mode": mode
                },
                headers=headers
            )
            response.raise_for_status()
            result = response.json()

            elapsed = time.time() - start_time
            mem_count = len(result['memories'])

            log_success(f"Mode '{mode}': {mem_count} memories in {elapsed*1000:.1f}ms")

        except Exception as e:
            log_error(f"Mode '{mode}' failed: {e}")
            return False

    return True

# =================================================================
# TEST 3: Preference Workflow
# =================================================================
def test_preferences():
    log_test("TEST 3: Preference Workflow (suggest/approve/reject)")

    # Suggest a preference with correct API format
    pref_data = {
        "content": "Always use type hints in Python function signatures",
        "category": "coding_standards",
        "confidence": 0.9,
        "session_id": "comprehensive_test",
        "detection_method": "explicit",
        "evidence": "Type hints improve code clarity and IDE support",
        "scope_type": "global",
        "project_id": "test_project"
    }

    try:
        # Suggest
        response = requests.post(f"{API_URL}/api/suggest_preference", json=pref_data, headers=headers)
        response.raise_for_status()
        pref_id = response.json()['preference_id']
        log_success(f"Suggested preference: {pref_id}")

        # Approve
        response = requests.post(
            f"{API_URL}/api/approve_preference",
            json={
                "preference_id": pref_id,
                "session_id": "comprehensive_test",
                "notes": "Approved via testing"
            },
            headers=headers
        )
        response.raise_for_status()
        log_success(f"Approved preference: {pref_id}")

        # Suggest another for rejection (using timestamp to make it unique)
        import time
        unique_suffix = str(int(time.time() * 1000))  # millisecond timestamp
        response = requests.post(f"{API_URL}/api/suggest_preference", json={
            "content": f"Use global variables for everything {unique_suffix}",
            "category": "coding_standards",
            "confidence": 0.3,
            "session_id": "comprehensive_test",
            "detection_method": "explicit",
            "project_id": "test_project"
        }, headers=headers)
        response.raise_for_status()
        pref_id2 = response.json()['preference_id']

        # Reject
        response = requests.post(
            f"{API_URL}/api/reject_preference",
            json={
                "preference_id": pref_id2,
                "session_id": "comprehensive_test",
                "reason": "Bad practice - globals are harmful"
            },
            headers=headers
        )
        response.raise_for_status()
        log_success(f"Rejected bad preference: {pref_id2}")

        return True

    except Exception as e:
        log_error(f"Preference workflow failed: {e}")
        return False

# =================================================================
# TEST 4: Memory Tiers and Promotion
# =================================================================
def test_memory_tiers():
    log_test("TEST 4: Memory Tiers (WORKING → EPISODIC promotion)")

    # Store a memory
    memory_data = {
        "content": "Critical algorithm: Use binary search for sorted arrays (O(log n) complexity)",
        "memory_type": "research_note",
        "context": {
            "session_id": "comprehensive_test",
            "role": "assistant",
            "task": "algorithm_optimization"
        },
        "tags": ["algorithm", "performance", "critical"]
    }

    try:
        response = requests.post(f"{API_URL}/api/store_memory", json=memory_data, headers=headers)
        response.raise_for_status()
        memory_id = response.json()['memory_id']
        log_success(f"Stored memory: {memory_id}")

        # Access it multiple times to simulate usage
        for i in range(3):
            response = requests.post(
                f"{API_URL}/api/retrieve_memories",
                json={
                    "query": "binary search algorithm optimization",
                    "top_k": 5,
                    "session_id": "comprehensive_test"
                },
                headers=headers
            )
            response.raise_for_status()

        log_success("Accessed memory 3 times (simulating usage)")
        log_info("Memory should promote to higher tiers with more usage")

        return True

    except Exception as e:
        log_error(f"Memory tiers test failed: {e}")
        return False

# =================================================================
# TEST 5: Concurrent Retrieval (Performance Test)
# =================================================================
def test_concurrent_retrieval():
    log_test("TEST 5: Concurrent Retrieval (50 sequential queries)")

    queries = [
        "code pattern for testing",
        "algorithm optimization techniques",
        "python type hints best practices",
        "binary search implementation",
        "batch processing strategies"
    ]

    start_time = time.time()
    successful = 0

    for i in range(50):
        query = queries[i % len(queries)]
        try:
            response = requests.post(
                f"{API_URL}/api/retrieve_memories",
                json={
                    "query": query,
                    "top_k": 3,
                    "session_id": "comprehensive_test",
                    "mode": "fast"
                },
                headers=headers,
                timeout=5
            )
            response.raise_for_status()
            successful += 1
        except Exception as e:
            log_error(f"Query {i} failed: {str(e)[:50]}")

    elapsed = time.time() - start_time
    log_success(f"{successful}/50 queries successful in {elapsed:.2f}s ({elapsed/50*1000:.1f}ms avg)")

    return successful >= 45  # Allow 10% failure

# =================================================================
# TEST 6: Large Memory Storage (Stress Test)
# =================================================================
def test_large_memory():
    log_test("TEST 6: Large Memory Storage (2000 char content)")

    large_content = """
    This is a comprehensive code pattern demonstrating a complex algorithm.
    """ * 50  # ~2000 characters

    memory_data = {
        "content": large_content,
        "memory_type": "code_pattern",
        "context": {
            "session_id": "comprehensive_test",
            "role": "assistant",
            "task": "large_content_test"
        },
        "tags": ["large", "stress_test"]
    }

    try:
        start_time = time.time()
        response = requests.post(f"{API_URL}/api/store_memory", json=memory_data, headers=headers)
        response.raise_for_status()
        elapsed = time.time() - start_time

        memory_id = response.json()['memory_id']
        log_success(f"Stored {len(large_content)} char memory in {elapsed*1000:.1f}ms: {memory_id}")

        return True

    except Exception as e:
        log_error(f"Large memory test failed: {e}")
        return False

# =================================================================
# TEST 7: System Health and Metrics
# =================================================================
def test_system_health():
    log_test("TEST 7: System Health Check")

    try:
        # Basic health
        response = requests.get(f"{API_URL}/health")
        response.raise_for_status()
        basic = response.json()
        log_success(f"Basic health: {basic['status']}")

        # Detailed health
        response = requests.get(f"{API_URL}/api/health/detailed", headers=headers)
        response.raise_for_status()
        detailed = response.json()

        log_info(f"Tier: {detailed['tier']['tier']}")
        log_info(f"Models: {', '.join(detailed['tier']['models_loaded'])}")

        for service, status in detailed['services'].items():
            if status['status'] == 'up':
                log_success(f"{service}: UP ({status['latency_ms']:.1f}ms)")
            else:
                log_error(f"{service}: DOWN")

        return True

    except Exception as e:
        log_error(f"Health check failed: {e}")
        return False

# =================================================================
# RUN ALL TESTS
# =================================================================
def run_all_tests():
    print(f"\n{Colors.BLUE}{'='*60}")
    print(f"  PRISM COMPREHENSIVE SYSTEM TEST SUITE")
    print(f"  Testing Tier 0 (Premium API Mode)")
    print(f"{'='*60}{Colors.END}\n")

    results = []
    stored_ids = []

    # Test 1: Batch Storage
    result = test_batch_storage()
    if isinstance(result, tuple):
        success, stored_ids = result
        results.append(("Batch Storage", success))
    else:
        results.append(("Batch Storage", result))

    # Test 2: Retrieval Modes
    results.append(("Retrieval Modes", test_retrieval_modes()))

    # Test 3: Preferences
    results.append(("Preference Workflow", test_preferences()))

    # Test 4: Memory Tiers
    results.append(("Memory Tiers", test_memory_tiers()))

    # Test 5: Concurrent Retrieval
    results.append(("Concurrent Retrieval", test_concurrent_retrieval()))

    # Test 6: Large Memory
    results.append(("Large Memory", test_large_memory()))

    # Test 7: System Health
    results.append(("System Health", test_system_health()))

    # Summary
    print(f"\n{Colors.BLUE}{'='*60}")
    print(f"  TEST SUMMARY")
    print(f"{'='*60}{Colors.END}\n")

    passed = sum(1 for _, success in results if success)
    total = len(results)

    for name, success in results:
        status = f"{Colors.GREEN}PASS{Colors.END}" if success else f"{Colors.RED}FAIL{Colors.END}"
        print(f"  {status}  {name}")

    print(f"\n{Colors.BLUE}Results: {passed}/{total} tests passed{Colors.END}\n")

    if passed == total:
        print(f"{Colors.GREEN}✓ ALL TESTS PASSED - System is production ready!{Colors.END}\n")
    else:
        print(f"{Colors.YELLOW}⚠ Some tests failed - review errors above{Colors.END}\n")

if __name__ == "__main__":
    run_all_tests()