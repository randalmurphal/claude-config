# Orchestration MCP V2 - Complete Rebuild

## Problem Statement
Current orchestration system is a metadata CRUD API built by Opus that can't actually orchestrate autonomous multi-hour tasks. It has no real validation, no checkpoints, no intelligent phase management, and doesn't scale to task complexity.

## User Impact
- Can't trust system for autonomous 30+ hour coding sessions
- No rollback when things fail (lose all progress)
- Self-validation is useless (agents lie about test results)
- Same workflow for 1-file and 100-file tasks (over/under-engineered)
- No learning from past tasks (Neo4j unused)

## Mission
Build bulletproof orchestration system that can autonomously handle tasks from 1 file to 100+ files with real validation, git-based checkpoints, parallel work isolation, and intelligent workflow scaling based on research from Anthropic/METR.

## Requirements (IMMUTABLE)

### Core Validation (Critical)
1. ✅ MUST actually run pytest, not ask if it passed
2. ✅ MUST check test coverage (>90% requirement)
3. ✅ MUST run linting (ruff with project/global config)
4. ✅ MUST validate imports work (python -m compileall)
5. ✅ MUST block phase transitions on validation failure

### Git-Based Checkpoints (Critical)
6. ✅ MUST create git commits after each validated phase
7. ✅ MUST support rollback to any checkpoint
8. ✅ MUST clean up checkpoint commits after task completion
9. ✅ MUST preserve checkpoint metadata in commit messages

### Parallel Work Isolation (Critical)
10. ✅ MUST use git worktrees for parallel module work
11. ✅ MUST intelligently merge worktrees (detect conflicts, pick best)
12. ✅ MUST validate after merge (ensure nothing broke)
13. ✅ MUST clean up worktrees after successful merge

### Neo4j Intelligence (Important)
14. ✅ MUST query similar past tasks for context
15. ✅ MUST retrieve relevant gotchas by task type/phase
16. ✅ MUST estimate time based on historical data
17. ✅ MUST store successful patterns for reuse

### Complexity Scaling (Important)
18. ✅ MUST auto-detect task complexity (small/medium/large/massive)
19. ✅ MUST adjust workflow to complexity (skip phases for small tasks)
20. ✅ MUST auto-decompose massive tasks (30+ files)
21. ✅ MUST recommend parallelization threshold by complexity

### Production Standards
22. ✅ MUST have 95%+ test coverage
23. ✅ MUST pass all linting (ruff)
24. ✅ MUST use type hints throughout
25. ✅ MUST have comprehensive error messages
26. ✅ MUST handle edge cases (no git repo, merge conflicts, etc.)

## Proposed Approach (EVOLVABLE)

### Architecture
**3-Layer Design:**
1. **Orchestrator (You/Claude)**: Strategic decisions, phase coordination, recovery
2. **MCP Server (Intelligence)**: Phase state machine, validation execution, checkpoint management, learning storage
3. **Worker Agents (Execution)**: Architecture planning, skeleton building, implementation, testing

### Phase State Machine (MCP-Enforced)
```
START → ARCHITECTURE → SKELETON → VALIDATE_SKELETON → CHECKPOINT
→ IMPLEMENTATION → VALIDATE_IMPLEMENTATION → CHECKPOINT
→ TESTING → VALIDATE_TESTING → CHECKPOINT
→ INTEGRATION (if multi-module) → VALIDATE_INTEGRATION
→ COMPLETE
```

Transitions blocked until validation passes.

### Implementation Modules

**Module 1: Validation System** (Independent)
- `validation_runner.py`: Execute pytest, linting, coverage
- `validation_parsers.py`: Parse pytest/ruff output
- Tests: Mock pytest output, verify parsing

**Module 2: Git Management** (Independent)
- `checkpoint_manager.py`: Create commits, rollback, list checkpoints
- `worktree_manager.py`: Create/merge worktrees, conflict resolution
- Tests: Test in temp git repo

**Module 3: Neo4j Intelligence** (Independent)
- Update `neo4j_manager.py`: Add query methods
- Similar task search, time estimation, gotcha retrieval
- Tests: Test against Neo4j test instance

**Module 4: Workflow Intelligence** (Depends on 1, 2, 3)
- `complexity_analyzer.py`: Auto-detect complexity
- `workflow_templates.yaml`: Workflow definitions
- `task_decomposer.py`: Break massive tasks into subtasks
- Tests: Verify complexity detection accuracy

**Module 5: MCP Integration** (Depends on all)
- Add tools to `mcp_server.py`
- Update `workflow_coordinator.py`
- Wire validation/checkpoints/worktrees
- Integration tests: Full workflow

## Success Criteria

### Functional Requirements
- [ ] Can validate Python project (pytest + coverage + linting)
- [ ] Can create checkpoint and rollback successfully
- [ ] Can create worktrees, work in parallel, merge intelligently
- [ ] Can query Neo4j for similar tasks and gotchas
- [ ] Can detect complexity and select appropriate workflow
- [ ] Can decompose 50-file task into 5 subtasks
- [ ] Blocks phase transitions on validation failure
- [ ] Full workflow: start → skeleton → validate → implement → validate → complete

### Quality Requirements
- [ ] 95%+ test coverage on all new modules
- [ ] All code passes ruff linting
- [ ] Type hints on all functions
- [ ] Error messages include what went wrong + how to fix
- [ ] Handles edge cases (no git, conflicts, etc.)

### Performance Requirements
- [ ] Validation runs in <30s for medium projects
- [ ] Checkpoint creation in <5s
- [ ] Worktree merge in <10s
- [ ] Neo4j queries in <1s

### Autonomous Operation
- [ ] Can run 3-hour task without human intervention
- [ ] Auto-creates checkpoints after validated phases
- [ ] Auto-rolls back on critical failures
- [ ] Provides clear progress updates

## Implementation Phases

### Phase 1: Validation System (6-8 hours)
**Skeleton:**
- validation_runner.py structure
- validation_parsers.py structure
- Test structure

**Implementation:**
- Execute pytest with coverage
- Execute ruff linting
- Parse pytest JSON output
- Parse ruff JSON output
- Check imports with compileall

**Testing:**
- Unit tests with mocked outputs
- Integration test on real project

**Validation:**
- 95%+ coverage on validation module
- Works on orchestration_mcp itself

### Phase 2: Git Management (8-10 hours)
**Skeleton:**
- checkpoint_manager.py structure
- worktree_manager.py structure
- Test structure

**Implementation:**
- Create git commits
- Parse commit history
- Rollback to checkpoint
- Create worktrees
- Merge worktrees with conflict detection
- Clean up worktrees/branches

**Testing:**
- Tests in temp git repo
- Test rollback scenarios
- Test merge conflicts

**Validation:**
- 95%+ coverage
- Works with real git repos

### Phase 3: Neo4j Intelligence (4-6 hours)
**Skeleton:**
- New methods in neo4j_manager.py

**Implementation:**
- find_similar_tasks()
- get_time_estimate()
- get_relevant_gotchas()
- record_successful_pattern()

**Testing:**
- Test against Neo4j
- Verify Cypher queries

**Validation:**
- Returns relevant results
- Handles empty database

### Phase 4: Workflow Intelligence (12-15 hours)
**Skeleton:**
- complexity_analyzer.py structure
- task_decomposer.py structure

**Implementation:**
- Analyze task complexity from description
- Count estimated files
- Select workflow template
- Decompose massive tasks
- Create subtask queue

**Testing:**
- Test complexity detection
- Test decomposition logic

**Validation:**
- Accurate complexity scoring
- Sensible task decomposition

### Phase 5: MCP Integration (8-10 hours)
**Skeleton:**
- New tool definitions in mcp_server.py

**Implementation:**
- validate_phase tool
- checkpoint tools (create/rollback/list)
- worktree tools (create/merge/cleanup)
- Update workflow_coordinator.py
- Wire everything together

**Testing:**
- Integration tests
- Full workflow test

**Validation:**
- All tools work end-to-end
- State management correct

### Phase 6: Real-World Validation (4-6 hours)
**Test Cases:**
- Small task (1-3 files)
- Medium task (5-10 files)
- Large task (15-25 files)
- Massive task (50+ files, decomposed)

**Scenarios:**
- Happy path (all passes)
- Test failures (validation blocks)
- Rollback scenario (checkpoint restore)
- Parallel work (worktree merge)

## Known Gotchas

### Git Management
- Worktree cleanup must handle partial failures
- Merge conflicts need smart resolution (not just first-wins)
- Checkpoint commits pollute history (need cleanup strategy)
- Rollback must clear Redis state after checkpoint

### Validation
- pytest might not be installed in all projects
- Coverage threshold might be too strict for some code
- Linting config varies by project
- Import checks fail on dynamic imports

### Parallel Work
- Worktrees only work in git repos
- Max worktrees limited by filesystem
- Merge conflicts need human review sometimes
- Performance degrades with >10 parallel modules

### Neo4j Queries
- Empty database returns no results (cold start problem)
- Similarity matching needs good keywords
- Time estimates unreliable with <5 samples
- Graph queries can be slow on large graphs

## Quality Requirements

### Testing
- 95%+ coverage on all new modules
- Unit tests for each function
- Integration tests for workflows
- Real-world tests on actual projects

### Code Quality
- Pass ruff linting with project config
- Type hints on all functions
- Docstrings in Google style
- Error messages include suggestions

### Documentation
- Update README.md to match reality
- Update SIMPLE_USAGE.md with new tools
- Update /conduct command with real workflow
- Create migration guide from V1 to V2

## Files to Create

### Services
- `orchestration_mcp/services/validation_runner.py` (~300 lines)
- `orchestration_mcp/services/validation_parsers.py` (~200 lines)
- `orchestration_mcp/services/checkpoint_manager.py` (~400 lines)
- `orchestration_mcp/services/worktree_manager.py` (~500 lines)
- `orchestration_mcp/services/complexity_analyzer.py` (~200 lines)
- `orchestration_mcp/services/task_decomposer.py` (~500 lines)

### Config
- `orchestration_mcp/config/workflows.yaml` (~100 lines)

### Tests
- `orchestration_mcp/tests/services/test_validation_runner.py`
- `orchestration_mcp/tests/services/test_checkpoint_manager.py`
- `orchestration_mcp/tests/services/test_worktree_manager.py`
- `orchestration_mcp/tests/services/test_complexity_analyzer.py`
- `orchestration_mcp/tests/services/test_task_decomposer.py`
- `orchestration_mcp/tests/integration/test_full_workflow.py`

## Files to Modify

### Core Services
- `orchestration_mcp/services/neo4j_manager.py` (add query methods)
- `orchestration_mcp/services/workflow_coordinator.py` (add validation/checkpoint hooks)
- `orchestration_mcp/mcp_server.py` (add new tools)

### Documentation
- `orchestration_mcp/README.md` (update to match V2)
- `orchestration_mcp/SIMPLE_USAGE.md` (add new examples)
- `~/.claude/commands/conduct.md` (remove phantom tools, show real workflow)
- `~/.claude/commands/prelude.md` (update READY.md format)

## Evolution Log
- 2025-09-29: Initial specification created for V2 rebuild based on research-backed architecture

---

**Ready for parallel agent execution**

Agents should be launched in parallel for:
- Module 1 (validation)
- Module 2 (git management)
- Module 3 (neo4j intelligence)

Then sequential for:
- Module 4 (workflow intelligence) - depends on 1, 2, 3
- Module 5 (MCP integration) - depends on all
- Module 6 (validation) - final testing