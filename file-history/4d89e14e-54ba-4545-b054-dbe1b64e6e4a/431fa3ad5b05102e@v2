# Phase 3: Tech Evolution Monitor - Design Document

**Date**: 2025-09-30
**Status**: Design Phase
**Estimated Duration**: 4-5 days

## Overview

Build an intelligent technology monitoring system that proactively tracks updates, deprecations, and security advisories for technologies in the user's stack. Integrates with Personal Claude to surface relevant updates based on architectural decisions.

---

## Goals

### Primary Goals
1. **Startup Quick-Check** (<5s): Check critical updates at session start
2. **Background Monitoring** (~5min): Full scan of 50 technologies
3. **ADR Integration**: Link updates to relevant architectural decisions
4. **Proactive Suggestions**: Generate actionable recommendations
5. **Zero False Positives**: Only surface truly relevant updates

### Non-Goals
- Real-time monitoring (batch checks are sufficient)
- Social media scraping (official sources only)
- Generic tech news (focus on user's stack only)

---

## Architecture

### Core Components

#### 1. TechEvolutionMonitor (Core Engine)
**Location**: `prism_mcp/core/tech_evolution_monitor.py`

**Responsibilities**:
- Track technologies in user's tech stack
- Coordinate update checking (startup + background)
- Store and retrieve update status
- Generate update summaries and suggestions

**Key Methods**:
```python
def check_critical_updates(session_id: str, user_id: str) -> List[CriticalUpdate]:
    """Quick check for critical updates (<5s)."""

def scan_full_stack(session_id: str, user_id: str, background: bool = True) -> ScanResult:
    """Full scan of all technologies (~5min)."""

def get_update_summary(session_id: str, tech_name: str) -> UpdateSummary:
    """Get summary of updates for specific technology."""

def link_updates_to_adrs(session_id: str, tech_name: str) -> List[ADRLink]:
    """Find ADRs that reference this technology."""

def generate_suggestions(session_id: str, updates: List[TechUpdate]) -> List[Suggestion]:
    """Generate actionable suggestions from updates."""
```

#### 2. WebSearchIntegration
**Location**: `prism_mcp/integrations/web_search.py`

**Responsibilities**:
- Search for tech updates using web search
- Parse release notes, changelogs, security advisories
- Extract structured data from search results
- Cache results to avoid repeated searches

**Search Sources**:
- Official release notes (GitHub releases, project websites)
- Security advisories (CVE databases, vendor advisories)
- Breaking change announcements
- Deprecation notices

**Key Methods**:
```python
def search_tech_updates(
    tech_name: str,
    current_version: Optional[str] = None,
    update_types: List[str] = ['security', 'breaking', 'deprecation']
) -> List[TechUpdate]:
    """Search for technology updates."""

def parse_release_notes(url: str) -> ReleaseInfo:
    """Parse release notes from URL."""

def check_cve_database(tech_name: str, version: str) -> List[SecurityAdvisory]:
    """Check CVE database for vulnerabilities."""
```

#### 3. TechStackTracker
**Location**: `prism_mcp/core/tech_stack_tracker.py`

**Responsibilities**:
- Extract technologies from user's tech opinions
- Track versions (from project files: package.json, requirements.txt, etc.)
- Maintain update check schedule
- Prioritize critical technologies

**Key Methods**:
```python
def get_user_tech_stack(session_id: str, user_id: str) -> List[Technology]:
    """Get user's technology stack from tech opinions."""

def detect_versions(project_path: str) -> Dict[str, str]:
    """Detect versions from project files."""

def prioritize_checks(technologies: List[Technology]) -> List[Technology]:
    """Prioritize critical/preferred technologies."""
```

#### 4. UpdateNotificationManager
**Location**: `prism_mcp/integrations/update_notifications.py`

**Responsibilities**:
- Format update notifications
- Filter by severity and relevance
- Store notification history
- Prevent notification spam

**Key Methods**:
```python
def format_update_notification(update: TechUpdate, adr_links: List[ADRLink]) -> str:
    """Format update as user-friendly notification."""

def should_notify(update: TechUpdate, user_id: str) -> bool:
    """Determine if update warrants notification."""

def mark_notified(update_id: str, user_id: str) -> None:
    """Mark update as notified to prevent duplicates."""
```

---

## Data Models

### Technology
```python
@dataclass
class Technology:
    name: str                    # "FastAPI", "PostgreSQL"
    category: str                # "framework", "database", "language"
    current_version: Optional[str]  # "0.104.1" (if detected)
    sentiment: str               # "prefer", "avoid", "neutral"
    last_checked: datetime
    next_check: datetime
    priority: int                # 1-5 (5 = critical)
    source: str                  # "tech_opinions", "project_files", "adrs"
```

### TechUpdate
```python
@dataclass
class TechUpdate:
    update_id: str               # UUID
    tech_name: str
    update_type: str             # "security", "breaking", "deprecation", "feature"
    severity: str                # "critical", "high", "medium", "low"
    version_from: Optional[str]  # Affected versions
    version_to: Optional[str]    # Fixed in version
    title: str                   # "Critical SQL injection vulnerability"
    summary: str                 # Brief description
    impact: str                  # What users need to do
    release_date: datetime
    source_url: str              # Link to release notes
    cve_id: Optional[str]        # If security advisory
    discovered_at: datetime
```

### CriticalUpdate (Subset for quick checks)
```python
@dataclass
class CriticalUpdate:
    tech_name: str
    severity: str                # "critical" only
    title: str
    impact: str                  # One-line action item
    source_url: str
```

### ADRLink
```python
@dataclass
class ADRLink:
    adr_id: str
    tech_name: str
    decision: str                # ADR decision summary
    relevance: float             # 0.0-1.0 (how relevant is update to ADR)
    impact_assessment: str       # "Decision still valid" / "Reconsider needed"
```

### UpdateSuggestion
```python
@dataclass
class UpdateSuggestion:
    suggestion_id: str
    tech_name: str
    suggestion_type: str         # "upgrade", "security_patch", "migrate", "deprecation_plan"
    priority: str                # "immediate", "soon", "planned"
    action: str                  # What to do
    reasoning: str               # Why this matters
    effort_estimate: str         # "hours", "days", "weeks"
    related_adrs: List[str]      # ADR IDs
```

---

## Performance Requirements

### Startup Quick-Check (<5s)
- Check only critical/preferred technologies (max 10)
- Use cached results if available (<24hrs old)
- Search for "critical" and "security" updates only
- Return immediately if no critical updates

**Implementation**:
```python
def check_critical_updates(session_id: str, user_id: str) -> List[CriticalUpdate]:
    # 1. Get top 10 critical techs from cache (Redis) - <10ms
    # 2. Check last scan time - if <24hrs, use cached results - <10ms
    # 3. For stale entries: Quick web search (parallel, 3s timeout) - <3s
    # 4. Parse and return critical updates only - <100ms
    # Total: <5s
```

### Background Scan (~5min for 50 technologies)
- Process technologies in parallel (10 concurrent)
- Each tech check: ~6s (search + parse)
- Cache results for 24-48 hours
- Run async, don't block user operations

**Implementation**:
```python
async def scan_full_stack(session_id: str, user_id: str) -> ScanResult:
    # 1. Get full tech stack - <100ms
    # 2. Group by priority (5 groups) - <10ms
    # 3. Process in batches of 10 (parallel) - ~30s per batch
    # 4. Store results in Redis + Neo4j - <5s total
    # Total: ~5min for 50 techs
```

---

## Redis Cache Schema

### Cache Keys
```
tech_stack:{user_id} → List of Technology objects (JSON)
tech_updates:{tech_name} → List of TechUpdate objects (JSON, 24hr TTL)
critical_updates:{user_id} → List of CriticalUpdate objects (JSON, 24hr TTL)
last_scan:{user_id} → Timestamp of last full scan
notifications:{user_id}:{update_id} → Notification status
```

### Cache Strategy
- **Tech Stack**: Update on preference changes, 7-day TTL
- **Tech Updates**: Per-technology cache, 24hr TTL
- **Critical Updates**: User-specific, 24hr TTL (force refresh on startup)
- **Last Scan**: Track background scan completion
- **Notifications**: Track shown notifications, 30-day TTL

---

## Integration Points

### 1. PersonalKnowledgeEngine → TechEvolutionMonitor
```python
# Get tech stack from tech opinions
tech_opinions = personal_engine.get_tech_stack(session_id, user_id)
technologies = tech_stack_tracker.extract_technologies(tech_opinions)
```

### 2. ADRManager → TechEvolutionMonitor
```python
# Link updates to ADRs
adrs = adr_manager.query_adrs(query=tech_name, session_id=session_id)
adr_links = tech_monitor.link_updates_to_adrs(session_id, tech_name)
```

### 3. ContextWarmer → TechEvolutionMonitor
```python
# Warm critical updates on session start
critical_updates = tech_monitor.check_critical_updates(session_id, user_id)
if critical_updates:
    context_warmer.warm_critical_updates(session_id, critical_updates)
```

### 4. UserPromptEnricher → Critical Updates
```python
# Inject critical update warnings into prompts
critical_updates = redis.get(f"critical_updates:{session_id}")
if critical_updates and query_type in ["architecture", "implementation"]:
    context.append(f"[CRITICAL_UPDATE: {update.title}]")
```

---

## Web Search Strategy

### Search Query Templates
```python
SEARCH_QUERIES = {
    'security': '{tech_name} security vulnerability CVE {year}',
    'breaking': '{tech_name} breaking changes version {version}',
    'deprecation': '{tech_name} deprecated features {year}',
    'release': '{tech_name} latest release notes {year}',
}
```

### URL Patterns (High-Quality Sources)
```python
TRUSTED_SOURCES = [
    'github.com/*/releases',
    '*.github.io',
    'docs.*.com',
    'blog.*.com',
    'cve.mitre.org',
    'nvd.nist.gov',
    'security.*.com',
]
```

### Rate Limiting
- Max 10 searches per second
- Max 100 searches per session
- Exponential backoff on rate limit errors
- Cache ALL search results (24hr minimum)

---

## Error Handling

### NO DEFAULTS Philosophy
```python
def check_critical_updates(session_id: str, user_id: str):
    if not session_id:
        raise RuntimeError('session_id required')
    if not user_id:
        raise RuntimeError('user_id required')

    # NO defaults - crash if tech stack retrieval fails
    tech_stack = self._get_tech_stack(user_id)  # Crash if missing

    # Graceful degradation for web search failures
    try:
        updates = self._search_updates(tech_stack)
    except Exception as e:
        logger.error(f'Update search failed: {e}')
        # Return cached results if available
        cached = self._get_cached_updates(user_id)
        if cached:
            logger.warning('Using cached updates due to search failure')
            return cached
        # If no cache, return empty (don't crash the session)
        logger.warning('No cached updates available, returning empty')
        return []
```

### Graceful Degradation
- Web search failures → use cached results (warn user)
- Parse failures → log and skip that result
- Timeout errors → partial results with warning
- Rate limit errors → queue for retry (background)

---

## Testing Strategy

### Unit Tests
- TechStackTracker: Extract technologies from opinions
- WebSearchIntegration: Parse release notes, CVE data
- UpdateNotificationManager: Format notifications, filter spam
- TechEvolutionMonitor: Link updates to ADRs, generate suggestions

### Integration Tests
- End-to-end: Startup check → background scan → notification
- Cache behavior: TTL, invalidation, refresh
- Error scenarios: Search failures, timeout, rate limits

### Performance Tests
- Startup check completes in <5s
- Background scan completes in <6min for 50 techs
- Cache reads <10ms
- Parallel search efficiency

---

## Success Metrics

### Functional
- ✅ Startup check completes in <5s
- ✅ Background scan completes in <6min for 50 techs
- ✅ Zero false positives (only relevant updates)
- ✅ ADR linking works correctly
- ✅ Suggestions are actionable

### Quality
- ✅ 95%+ test coverage
- ✅ NO DEFAULTS philosophy enforced
- ✅ Graceful error handling
- ✅ Comprehensive logging
- ✅ Cache efficiency (>90% hit rate after first scan)

---

## Implementation Phases

### Phase 3A: Core Engine (Days 1-2)
- TechEvolutionMonitor class
- TechStackTracker class
- Data models (Technology, TechUpdate, etc.)
- Redis cache integration
- Basic tests

### Phase 3B: Web Search (Days 2-3)
- WebSearchIntegration class
- Search query templates
- Result parsing
- Rate limiting
- Caching strategy

### Phase 3C: Startup + Background (Days 3-4)
- Startup quick-check implementation
- Background scan system (async)
- ADR linking
- Suggestion generation

### Phase 3D: Integration + Testing (Days 4-5)
- ContextWarmer integration
- UserPromptEnricher integration
- Comprehensive tests
- Performance validation
- Documentation

---

## Files to Create

### Core
- `prism_mcp/core/tech_evolution_monitor.py` (~400 lines)
- `prism_mcp/core/tech_stack_tracker.py` (~250 lines)

### Integrations
- `prism_mcp/integrations/web_search.py` (~350 lines)
- `prism_mcp/integrations/update_notifications.py` (~200 lines)

### Tests
- `tests/test_tech_evolution_monitor.py` (~300 lines)
- `tests/test_tech_stack_tracker.py` (~150 lines)
- `tests/test_web_search.py` (~200 lines)

### Documentation
- `docs/PHASE_3_COMPLETE.md` (summary + examples)

**Total Estimated Lines**: ~1,850 lines of production code

---

## Next Steps

1. ✅ Review and approve design
2. Create data models and base classes
3. Implement TechStackTracker
4. Implement WebSearchIntegration
5. Implement TechEvolutionMonitor
6. Add ContextWarmer integration
7. Write comprehensive tests
8. Validate performance requirements
9. Document and mark complete